{
 "cells": [
  {
   "cell_type": "raw",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics\n",
    "In this notebook we will calculate and plot the metrics coming from the YOLO training runs.\n",
    "\n",
    "# Load Data\n",
    "As a first step, let's fetch the results from our training run."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T19:25:57.516390200Z",
     "start_time": "2023-12-11T19:25:57.496998900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 20.8M    0 88891    0     0   109k      0  0:03:15 --:--:--  0:03:15  109k\n",
      "  2 20.8M    2  494k    0     0   279k      0  0:01:16  0:00:01  0:01:15  279k\n",
      "  4 20.8M    4 1055k    0     0   380k      0  0:00:56  0:00:02  0:00:54  380k\n",
      "  7 20.8M    7 1497k    0     0   395k      0  0:00:53  0:00:03  0:00:50  396k\n",
      "  8 20.8M    8 1871k    0     0   391k      0  0:00:54  0:00:04  0:00:50  392k\n",
      " 10 20.8M   10 2245k    0     0   389k      0  0:00:54  0:00:05  0:00:49  433k\n",
      " 11 20.8M   11 2466k    0     0   363k      0  0:00:58  0:00:06  0:00:52  393k\n",
      " 12 20.8M   12 2653k    0     0   340k      0  0:01:02  0:00:07  0:00:55  317k\n",
      " 13 20.8M   13 2874k    0     0   327k      0  0:01:05  0:00:08  0:00:57  275k\n",
      " 14 20.8M   14 3010k    0     0   306k      0  0:01:09  0:00:09  0:01:00  225k\n",
      " 14 20.8M   14 3146k    0     0   291k      0  0:01:13  0:00:10  0:01:03  179k\n",
      " 15 20.8M   15 3282k    0     0   277k      0  0:01:16  0:00:11  0:01:05  162k\n",
      " 16 20.8M   16 3418k    0     0   265k      0  0:01:20  0:00:12  0:01:08  151k\n",
      " 16 20.8M   16 3537k    0     0   256k      0  0:01:23  0:00:13  0:01:10  131k\n",
      " 17 20.8M   17 3741k    0     0   253k      0  0:01:24  0:00:14  0:01:10  147k\n",
      " 18 20.8M   18 3945k    0     0   250k      0  0:01:25  0:00:15  0:01:10  160k\n",
      " 19 20.8M   19 4149k    0     0   247k      0  0:01:26  0:00:16  0:01:10  174k\n",
      " 20 20.8M   20 4285k    0     0   240k      0  0:01:28  0:00:17  0:01:11  176k\n",
      " 20 20.8M   20 4455k    0     0   236k      0  0:01:30  0:00:18  0:01:12  181k\n",
      " 21 20.8M   21 4642k    0     0   232k      0  0:01:31  0:00:19  0:01:12  174k\n",
      " 22 20.8M   22 4693k    0     0   219k      0  0:01:36  0:00:21  0:01:15  134k\n",
      " 22 20.8M   22 4744k    0     0   215k      0  0:01:38  0:00:22  0:01:16  113k\n",
      " 22 20.8M   22 4778k    0     0   205k      0  0:01:43  0:00:23  0:01:20 92189\n",
      " 22 20.8M   22 4863k    0     0   204k      0  0:01:44  0:00:23  0:01:21 84934\n",
      " 23 20.8M   23 5067k    0     0   204k      0  0:01:44  0:00:24  0:01:20 89917\n",
      " 24 20.8M   24 5305k    0     0   205k      0  0:01:43  0:00:25  0:01:18  138k\n",
      " 26 20.8M   26 5543k    0     0   206k      0  0:01:43  0:00:26  0:01:17  167k\n",
      " 27 20.8M   27 5849k    0     0   210k      0  0:01:41  0:00:27  0:01:14  237k\n",
      " 29 20.8M   29 6274k    0     0   217k      0  0:01:37  0:00:28  0:01:09  282k\n",
      " 31 20.8M   31 6750k    0     0   226k      0  0:01:34  0:00:29  0:01:05  335k\n",
      " 33 20.8M   33 7192k    0     0   233k      0  0:01:31  0:00:30  0:01:01  376k\n",
      " 34 20.8M   34 7362k    0     0   231k      0  0:01:32  0:00:31  0:01:01  364k\n",
      " 35 20.8M   35 7583k    0     0   231k      0  0:01:32  0:00:32  0:01:00  346k\n",
      " 37 20.8M   37 7956k    0     0   235k      0  0:01:30  0:00:33  0:00:57  337k\n",
      " 39 20.8M   39 8399k    0     0   241k      0  0:01:28  0:00:34  0:00:54  331k\n",
      " 41 20.8M   41 8807k    0     0   246k      0  0:01:26  0:00:35  0:00:51  323k\n",
      " 42 20.8M   42 9130k    0     0   248k      0  0:01:25  0:00:36  0:00:49  355k\n",
      " 44 20.8M   44 9436k    0     0   249k      0  0:01:25  0:00:37  0:00:48  369k\n",
      " 45 20.8M   45 9742k    0     0   251k      0  0:01:24  0:00:38  0:00:46  356k\n",
      " 47 20.8M   47  9.8M    0     0   253k      0  0:01:24  0:00:39  0:00:45  334k\n",
      " 49 20.8M   49 10.2M    0     0   256k      0  0:01:23  0:00:40  0:00:43  329k\n",
      " 50 20.8M   50 10.5M    0     0   259k      0  0:01:22  0:00:41  0:00:41  344k\n",
      " 52 20.8M   52 10.8M    0     0   260k      0  0:01:21  0:00:42  0:00:39  342k\n",
      " 54 20.8M   54 11.2M    0     0   263k      0  0:01:20  0:00:43  0:00:37  354k\n",
      " 56 20.8M   56 11.7M    0     0   267k      0  0:01:19  0:00:44  0:00:35  381k\n",
      " 58 20.8M   58 12.1M    0     0   271k      0  0:01:18  0:00:45  0:00:33  394k\n",
      " 59 20.8M   59 12.4M    0     0   272k      0  0:01:18  0:00:46  0:00:32  377k\n",
      " 61 20.8M   61 12.7M    0     0   273k      0  0:01:18  0:00:47  0:00:31  380k\n",
      " 62 20.8M   62 13.1M    0     0   274k      0  0:01:17  0:00:48  0:00:29  377k\n",
      " 64 20.8M   64 13.5M    0     0   277k      0  0:01:16  0:00:49  0:00:27  369k\n",
      " 67 20.8M   67 13.9M    0     0   281k      0  0:01:15  0:00:50  0:00:25  370k\n",
      " 67 20.8M   67 14.1M    0     0   279k      0  0:01:16  0:00:51  0:00:25  345k\n",
      " 68 20.8M   68 14.3M    0     0   278k      0  0:01:16  0:00:52  0:00:24  325k\n",
      " 70 20.8M   70 14.5M    0     0   277k      0  0:01:16  0:00:53  0:00:23  303k\n",
      " 71 20.8M   71 14.7M    0     0   276k      0  0:01:17  0:00:54  0:00:23  258k\n",
      " 72 20.8M   72 15.0M    0     0   276k      0  0:01:17  0:00:55  0:00:22  223k\n",
      " 73 20.8M   73 15.3M    0     0   277k      0  0:01:16  0:00:56  0:00:20  259k\n",
      " 75 20.8M   75 15.6M    0     0   276k      0  0:01:17  0:00:57  0:00:20  261k\n",
      " 75 20.8M   75 15.7M    0     0   274k      0  0:01:17  0:00:58  0:00:19  245k\n",
      " 76 20.8M   76 16.0M    0     0   274k      0  0:01:17  0:00:59  0:00:18  252k\n",
      " 77 20.8M   77 16.1M    0     0   272k      0  0:01:18  0:01:00  0:00:18  234k\n",
      " 78 20.8M   78 16.3M    0     0   270k      0  0:01:18  0:01:01  0:00:17  193k\n",
      " 79 20.8M   79 16.5M    0     0   269k      0  0:01:19  0:01:02  0:00:17  190k\n",
      " 80 20.8M   80 16.6M    0     0   267k      0  0:01:19  0:01:03  0:00:16  182k\n",
      " 80 20.8M   80 16.8M    0     0   265k      0  0:01:20  0:01:04  0:00:16  163k\n",
      " 81 20.8M   81 16.9M    0     0   263k      0  0:01:20  0:01:05  0:00:15  157k\n",
      " 82 20.8M   82 17.1M    0     0   263k      0  0:01:20  0:01:06  0:00:14  173k\n",
      " 83 20.8M   83 17.3M    0     0   261k      0  0:01:21  0:01:07  0:00:14  158k\n",
      " 83 20.8M   83 17.4M    0     0   259k      0  0:01:22  0:01:08  0:00:14  161k\n",
      " 85 20.8M   85 17.7M    0     0   259k      0  0:01:22  0:01:09  0:00:13  184k\n",
      " 86 20.8M   86 18.0M    0     0   260k      0  0:01:21  0:01:10  0:00:11  217k\n",
      " 88 20.8M   88 18.4M    0     0   262k      0  0:01:21  0:01:11  0:00:10  255k\n",
      " 91 20.8M   91 18.9M    0     0   266k      0  0:01:19  0:01:12  0:00:07  335k\n",
      " 93 20.8M   93 19.5M    0     0   271k      0  0:01:18  0:01:13  0:00:05  429k\n",
      " 95 20.8M   95 19.9M    0     0   272k      0  0:01:18  0:01:14  0:00:04  452k\n",
      " 96 20.8M   96 20.1M    0     0   271k      0  0:01:18  0:01:15  0:00:03  428k\n",
      " 97 20.8M   97 20.2M    0     0   269k      0  0:01:18  0:01:16  0:00:02  371k\n",
      " 98 20.8M   98 20.4M    0     0   268k      0  0:01:19  0:01:17  0:00:02  292k\n",
      " 98 20.8M   98 20.5M    0     0   266k      0  0:01:19  0:01:18  0:00:01  203k\n",
      " 99 20.8M   99 20.7M    0     0   265k      0  0:01:20  0:01:19  0:00:01  163k\n",
      "100 20.8M  100 20.8M    0     0   266k      0  0:01:20  0:01:20 --:--:--  166k\n"
     ]
    }
   ],
   "source": [
    "!curl -L https://aml-2023.s3.eu-north-1.amazonaws.com/final-project/yolo_runs_epoch_90.zip > yolo_runs_epoch_90.zip"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T19:27:59.530079100Z",
     "start_time": "2023-12-11T19:26:39.217144800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And extract into a chosen directory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "run_data_dir = \"run_data\"\n",
    "Path(run_data_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "with zipfile.ZipFile(\"yolo_runs_epoch_90.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(run_data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T19:56:34.531621400Z",
     "start_time": "2023-12-11T19:56:33.834087100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's load the run dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_results = pd.read_csv(\"data/yolo_runs_epoch_90/runs/detect/train/results.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, let's fetch the training and validation data. This we need for the validation of the YOLO model at the end."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!fetch_data.sh --type yolo --output garbage_sub --percentage subset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extract Train and Validation Results\n",
    "Then, we extract the training and validation columns from the dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "train_columns = list(filter(lambda col_name: \"train\" in col_name, run_results.columns))\n",
    "train_results = run_results[train_columns]\n",
    "\n",
    "val_columns = list(filter(lambda col_name: \"val\" in col_name, run_results.columns))\n",
    "val_results = run_results[val_columns]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T17:15:27.717840500Z",
     "start_time": "2023-12-11T17:15:27.636715800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the output directory if it doesn't already exist."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "Path(\"metrics_plots\").mkdir(exist_ok=True, parents=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T17:15:27.718842700Z",
     "start_time": "2023-12-11T17:15:27.651856300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot\n",
    "Create a function to plot the loss and save it if requested. We always plot the training and validation loss values for a specific type of loss together, e.g. box loss."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def plot_loss(train, val, name, save=False, save_dir=None, save_format=\"svg\"):\n",
    "    \"\"\"Creates a figure, axis tuple for the train and validation losses.\n",
    "\n",
    "    To save the plot, both the save and save_dir parameters must be set. Images will be saved as svg by default.\n",
    "\n",
    "    :arg\n",
    "        train - an iterable of the training loss.\n",
    "        val - an iterable of the validation loss.\n",
    "        name - the name of the loss, e.g. box loss. This will be the title of the plot.\n",
    "        save - whether to save the plot.\n",
    "        save_dir - the directory where to save the plot, must exist before calling this function.\n",
    "        save_format - the format to save the plot in, default is svg.\n",
    "\n",
    "    :return\n",
    "        fig, ax - the figure and axis object of the plot.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(train, label=\"Train\")\n",
    "    ax.plot(val, label=\"Val\")\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "    if save and save_dir:\n",
    "        file_name = f\"{name.replace(' ', '_')}.{save_format}\"\n",
    "        fig.savefig(os.path.join(save_dir, file_name), format=save_format)\n",
    "    return fig, ax"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T17:15:27.721839600Z",
     "start_time": "2023-12-11T17:15:27.704549100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we call the `plot_loss` method to create and save the loss plots in the specified directory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "(<Figure size 640x480 with 1 Axes>,\n <Axes: title={'center': 'Distributional Focal Loss'}, xlabel='Epoch', ylabel='Loss'>)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_loss(train_results.iloc[:, 0], val_results.iloc[:, 0], \"Box Loss\", save=True, save_dir=\"metrics_plots\")\n",
    "plot_loss(train_results.iloc[:, 1], val_results.iloc[:, 1], \"Classification Loss\", save=True, save_dir=\"metrics_plots\")\n",
    "plot_loss(train_results.iloc[:, 2], val_results.iloc[:, 2], \"Distributional Focal Loss\", save=True, save_dir=\"metrics_plots\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T17:15:28.362826900Z",
     "start_time": "2023-12-11T17:15:27.712843300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification Metrics\n",
    "Next, let's do the classification metrics:\n",
    "\n",
    "* precision\n",
    "* precision-recall\n",
    "* F1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics.nn.tasks import DetectionModel\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T18:19:20.869911700Z",
     "start_time": "2023-12-11T18:19:20.832131200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup Model\n",
    "As a first step, we need to setup up the model by doing the following:\n",
    "\n",
    "1. Create a `DetectionModel` with the garbage architecture, basically just use a single class instead of the many that are normally used.\n",
    "2. Load the best weights from the training into this model.\n",
    "3. Create the YOLO model with the same best weights and with a detection task, since we want to do object detection here.\n",
    "4. Assign the detection model to the `model` field of the YOLO object. This is a bit hacky but it's the only way we can let YOLO know that it should only predict a single class."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n"
     ]
    }
   ],
   "source": [
    "det = DetectionModel(\"model.yaml\")\n",
    "det.load(torch.load(\"data/yolo_runs_epoch_90/runs/detect/train/weights/best.pt\"))\n",
    "model = YOLO(model=\"data/yolo_runs_epoch_90/runs/detect/train/weights/best.pt\", task=\"detect\")  # load a pretrained model (recommended for training)\n",
    "model.model = det"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T18:19:24.107057600Z",
     "start_time": "2023-12-11T18:19:21.667607500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Validation\n",
    "Next, we validate the model on the **test** data by simply calling the `val` method with the path to the `.yaml` file where we specify the dataset. This will return a `Metrics` object from which we can access all the metrics we are interested in."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.225 ðŸš€ Python-3.9.0 torch-2.1.1+cpu CPU (Intel Core(TM) i5-6200U 2.30GHz)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\Jonas\\Desktop\\Uni\\MSc\\Year-2\\AML\\Assignments\\final-project\\final-project\\garbage_sub\\valid\\labels.cache... 28 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         28         31      0.899      0.577      0.713       0.42\n",
      "Speed: 7.9ms preprocess, 389.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001B[1mC:\\Users\\Jonas\\Desktop\\Uni\\MSc\\Year-2\\AML\\Assignments\\final-project\\final-project\\runs\\detect\\val4\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Validate the model\n",
    "data_path = os.path.abspath(\"garbage_sub/data.yaml\")\n",
    "metrics = model.val(data=data_path)  # no arguments needed, dataset and settings remembered"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T19:02:06.135993200Z",
     "start_time": "2023-12-11T19:01:43.874842200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting the Metrics\n",
    "Now, let's plot the metrics. First, let's create a plot function that we can reuse, similar to the `plot_loss` function above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "def plot_metric(data, xlabel, ylabel, title, save=False, save_dir=None, save_format=\"svg\"):\n",
    "    \"\"\"Plots a metric of the YOLOv8 model.\n",
    "\n",
    "    arg:\n",
    "        data - the data to plot. Should just be a single variable (statistically speaking).\n",
    "        xlabel - the label of the x axis.\n",
    "        ylabel - the label of the y axis.\n",
    "        title - the title of the plot.\n",
    "        save - whether to save the plot.\n",
    "        save_dir - the directory where to save the plot, must exist before calling this function.\n",
    "        save_format - the format to save the plot in, default is svg.\n",
    "\n",
    "    :return\n",
    "        fig, ax - the figure and axis object of the plot.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(data)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    ax.grid(True)\n",
    "\n",
    "    if save and save_dir:\n",
    "        file_name = f\"{title.replace(' ', '_')}.{save_format}\"\n",
    "        fig.savefig(os.path.join(save_dir, file_name), format=save_format)\n",
    "    return fig, ax"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T19:10:00.988458700Z",
     "start_time": "2023-12-11T19:10:00.952422Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Precision\n",
    "Precision is a measurement of how many of our predicted true positives are actually true positives:\n",
    "\n",
    "$$\n",
    "precision = \\frac{TP}{TP + FP}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "(<Figure size 640x480 with 1 Axes>,\n <Axes: title={'center': 'Precision-Confidence'}, xlabel='Confidence', ylabel='Precision'>)"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_metric(metrics.box.p_curve.T, \"Confidence\", \"Precision\", \"Precision-Confidence\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T19:10:03.158108800Z",
     "start_time": "2023-12-11T19:10:03.088260600Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
