{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPFrKxLsAad73/EJIrgJ1AD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aml-2023/final-project/blob/yolo/yolo_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone YOLO v7\n",
        "As a first step, we will clone the yolov7 code with which we will work. We also move inside the `yolov7` directory, because all the work will be done in there."
      ],
      "metadata": {
        "id": "ePFmPOBvPODT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7.git\n",
        "%cd yolov7"
      ],
      "metadata": {
        "id": "KCkz30MHK9rh",
        "outputId": "e1ac1d0e-3465-4127-debe-6631a6f61010",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1197, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 1197 (delta 2), reused 3 (delta 1), pack-reused 1191\u001b[K\n",
            "Receiving objects: 100% (1197/1197), 74.23 MiB | 7.92 MiB/s, done.\n",
            "Resolving deltas: 100% (517/517), done.\n",
            "/content/yolov7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the needed packages for `yolo`."
      ],
      "metadata": {
        "id": "FBCmTia7Pbo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "id": "5MkYVWCqLI7Y",
        "outputId": "29cc57eb-be5c-456c-ca0d-d5591ee38560",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the YOLO weights\n",
        "This will download the latest version of the YOLOv7-tiny model which has been pre-trained on the COCO dataset."
      ],
      "metadata": {
        "id": "8uGygs2vPfCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMx7RCOAuUZm",
        "outputId": "179a984c-e23b-4170-c1fc-4c0360523e04"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-07 10:27:58--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/ba7d01ee-125a-4134-8864-fa1abcbf94d5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231207%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231207T102758Z&X-Amz-Expires=300&X-Amz-Signature=122c1c894dd31bdf123a94ffd4cf44f5e49915ced0ed68400f928620b6d8ce7f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7-tiny.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-12-07 10:27:58--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/ba7d01ee-125a-4134-8864-fa1abcbf94d5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231207%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231207T102758Z&X-Amz-Expires=300&X-Amz-Signature=122c1c894dd31bdf123a94ffd4cf44f5e49915ced0ed68400f928620b6d8ce7f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7-tiny.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12639769 (12M) [application/octet-stream]\n",
            "Saving to: â€˜yolov7-tiny.ptâ€™\n",
            "\n",
            "yolov7-tiny.pt      100%[===================>]  12.05M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-12-07 10:27:58 (196 MB/s) - â€˜yolov7-tiny.ptâ€™ saved [12639769/12639769]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch Data\n",
        "Then, we will fetch our garbage data in the YOLO format and save inside a new `garbage` directory."
      ],
      "metadata": {
        "id": "gFW3Uj8hPoxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O fetch_data.sh https://raw.githubusercontent.com/aml-2023/final-project/main/fetch_data.sh\n",
        "!bash fetch_data.sh --type yolo --output garbage"
      ],
      "metadata": {
        "id": "NHrQaxHGLwyh",
        "outputId": "850a6902-df0e-4f2a-e633-c11c79fde915",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-07 10:27:59--  https://raw.githubusercontent.com/aml-2023/final-project/main/fetch_data.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1222 (1.2K) [text/plain]\n",
            "Saving to: â€˜fetch_data.shâ€™\n",
            "\n",
            "fetch_data.sh       100%[===================>]   1.19K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-07 10:27:59 (92.6 MB/s) - â€˜fetch_data.shâ€™ saved [1222/1222]\n",
            "\n",
            "Downloading data\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   894  100   894    0     0    519      0  0:00:01  0:00:01 --:--:--   519\n",
            "100  274M  100  274M    0     0  26.0M      0  0:00:10  0:00:10 --:--:-- 33.8M\n",
            "Data downloaded and extracted into garbage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overwrite Default YAML\n",
        "YOLO expects to find a `.yaml` file that specifies where to find the train, val, test images, how many classes there are etc. The default file that we are given has incorrect paths for train, val, and test, so we change it to match the correct path (the code is run from the root of the `yolo` folder, so any paths need to reflect that)."
      ],
      "metadata": {
        "id": "SNhbh-w8PwaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile garbage/data.yaml\n",
        "train: garbage/train\n",
        "val: garbage/valid\n",
        "test: garbage/test\n",
        "\n",
        "# Classes\n",
        "nc: 1  # number of classes\n",
        "names: ['garbage']  # class names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxxBaKZ-vv-p",
        "outputId": "0216fb52-a882-4b34-940c-4884e1f84176"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting garbage/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subsetting the Data\n",
        "To train the YOLO model a lot more, we can subset the data, by copying over $p$% of image and label files into a new directory."
      ],
      "metadata": {
        "id": "Qx0OwLoeylLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pathlib\n",
        "\n",
        "def label_path_from_image_path(image_path: str, base_path):\n",
        "    \"\"\"Gets the YOLO label path from the image path.\"\"\"\n",
        "    label = image_path.split(\"/\")[-1]\n",
        "    label = label[:-3] + \"txt\"\n",
        "    label = os.path.join(base_path, label)\n",
        "    return label\n",
        "\n",
        "\n",
        "def get_image_label_path_pair(base_path: str, split_folder: str):\n",
        "    \"\"\"Gets all the image and label path pairs for a specific base path and the split folder, e.g. garbage and test.\"\"\"\n",
        "    img_path = os.path.join(base_path, split_folder, \"images\")\n",
        "    labels_path = os.path.join(base_path, split_folder, \"labels\")\n",
        "\n",
        "    pairs = []\n",
        "    for image_name in glob(f\"{img_path}/*.jpg\"):\n",
        "        label = label_path_from_image_path(image_name, labels_path)\n",
        "        pairs.append((image_name, label))\n",
        "\n",
        "    return pairs\n",
        "\n",
        "\n",
        "def subset_split_folder(yolo_root_dir: str, percentage: float, split_folder: str, out_dir: str):\n",
        "    \"\"\"Subsets a split folder (train, test, valid) and copies the subset to a new directory.\"\"\"\n",
        "    pairs = get_image_label_path_pair(yolo_root_dir, split_folder)\n",
        "    subset_len = int(len(pairs) * percentage)\n",
        "    subset_idx = np.random.randint(low=0, high=len(pairs), size=subset_len)\n",
        "\n",
        "    subset_pairs = [pairs[i] for i in subset_idx]\n",
        "\n",
        "    out_dir_img = os.path.join(out_dir, split_folder, \"images\")\n",
        "    out_dir_labels = os.path.join(out_dir, split_folder, \"labels\")\n",
        "\n",
        "    pathlib.Path(out_dir_img).mkdir(parents=True, exist_ok=True)\n",
        "    pathlib.Path(out_dir_labels).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for img, label in subset_pairs:\n",
        "        dest_img_path = os.path.join(out_dir_img, img.split(\"/\")[-1])\n",
        "        dest_label_path = os.path.join(out_dir_labels, label.split(\"/\")[-1])\n",
        "\n",
        "        shutil.copy(img, dest_img_path)\n",
        "        shutil.copy(label, dest_label_path)\n",
        "\n",
        "def subset_yolo_data(yolo_root_dir: str, percentage: float, out_dir: str):\n",
        "    \"\"\"Subsets the YOLO dataset by taking a percentage of the original data and moving it into a new directory.\n",
        "\n",
        "    :arg\n",
        "        yolo_root_dir (str): the root directory where the yolo data is.\n",
        "        percentage (float): the percentage of images to keep.\n",
        "        out_dir (str): the output directory, will be created if it does not exist.\n",
        "    \"\"\"\n",
        "    subset_split_folder(yolo_root_dir, percentage, \"train\", out_dir)\n",
        "    subset_split_folder(yolo_root_dir, percentage, \"test\", out_dir)\n",
        "    subset_split_folder(yolo_root_dir, percentage, \"valid\", out_dir)\n",
        "\n",
        "    other_files = [\"README.dataset.txt\", \"README.roboflow.txt\", \"data.yaml\"]\n",
        "\n",
        "    for file in other_files:\n",
        "        old_path = os.path.join(yolo_root_dir, file)\n",
        "        new_path = os.path.join(out_dir, file)\n",
        "        shutil.copy(old_path, new_path)\n"
      ],
      "metadata": {
        "id": "YZ0YlYi5gQOP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subset_yolo_data(\"garbage\", 0.1, \"garbage_sub\")"
      ],
      "metadata": {
        "id": "npeWzz-IjdyZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, we need to overwrite the `.yaml` file in the newly created subset garbage folder."
      ],
      "metadata": {
        "id": "2OsFxjJZz95R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile garbage_sub/data.yaml\n",
        "train: garbage_sub/train\n",
        "val: garbage_sub/valid\n",
        "test: garbage_sub/test\n",
        "\n",
        "# Classes\n",
        "nc: 1  # number of classes\n",
        "names: ['garbage']  # class names"
      ],
      "metadata": {
        "id": "1Bb9WJc_z6cp",
        "outputId": "1496ddc6-6908-44fc-c599-98b2581b83c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting garbage_sub/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure YOLO model\n",
        "Next, we need to configure the YOLOv7-tiny model for the garbage dataset training. There are several default configuration files inside `yolov7/cfg/training/` directory. All these contain the model configuration. We need to configure the `yolov7-tiny.yaml` file. For that, we will create a copy of that file, rename it, and configure it accordingly.\n",
        "\n",
        "The following code block creates a `yolov7_garbage-tiny.yaml` file."
      ],
      "metadata": {
        "id": "W0SLvp78QP1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cfg/training/yolov7_garbage-tiny.yaml\n",
        "# parameters\n",
        "nc: 1  # number of classes\n",
        "depth_multiple: 1.0  # model depth multiple\n",
        "width_multiple: 1.0  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# yolov7-tiny backbone\n",
        "backbone:\n",
        "  # [from, number, module, args] c2, k=1, s=1, p=None, g=1, act=True\n",
        "  [[-1, 1, Conv, [32, 3, 2, None, 1, nn.LeakyReLU(0.1)]],  # 0-P1/2\n",
        "\n",
        "  [-1, 1, Conv, [64, 3, 2, None, 1, nn.LeakyReLU(0.1)]],  # 1-P2/4\n",
        "\n",
        "  [-1, 1, Conv, [32, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-2, 1, Conv, [32, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, Conv, [32, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, Conv, [32, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "  [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 7\n",
        "\n",
        "  [-1, 1, MP, []],  # 8-P3/8\n",
        "  [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-2, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "  [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 14\n",
        "\n",
        "  [-1, 1, MP, []],  # 15-P4/16\n",
        "  [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-2, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, Conv, [128, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, Conv, [128, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "  [-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 21\n",
        "\n",
        "  [-1, 1, MP, []],  # 22-P5/32\n",
        "  [-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-2, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, Conv, [256, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, Conv, [256, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "  [-1, 1, Conv, [512, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 28\n",
        "  ]\n",
        "\n",
        "# yolov7-tiny head\n",
        "head:\n",
        "  [[-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-2, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, SP, [5]],\n",
        "  [-2, 1, SP, [9]],\n",
        "  [-3, 1, SP, [13]],\n",
        "  [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "  [-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [[-1, -7], 1, Concat, [1]],\n",
        "  [-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 37\n",
        "\n",
        "  [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "  [21, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]], # route backbone P4\n",
        "  [[-1, -2], 1, Concat, [1]],\n",
        "\n",
        "  [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-2, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "  [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 47\n",
        "\n",
        "  [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "  [14, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]], # route backbone P3\n",
        "  [[-1, -2], 1, Concat, [1]],\n",
        "\n",
        "  [-1, 1, Conv, [32, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-2, 1, Conv, [32, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, Conv, [32, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, Conv, [32, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "  [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 57\n",
        "\n",
        "  [-1, 1, Conv, [128, 3, 2, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [[-1, 47], 1, Concat, [1]],\n",
        "\n",
        "  [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-2, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "  [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 65\n",
        "\n",
        "  [-1, 1, Conv, [256, 3, 2, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [[-1, 37], 1, Concat, [1]],\n",
        "\n",
        "  [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-2, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, Conv, [128, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [-1, 1, Conv, [128, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "  [-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 73\n",
        "\n",
        "  [57, 1, Conv, [128, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [65, 1, Conv, [256, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "  [73, 1, Conv, [512, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "\n",
        "  [[74,75,76], 1, IDetect, [nc, anchors]],   # Detect(P3, P4, P5)\n",
        "  ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdFwM7PLwjZg",
        "outputId": "979f75ec-c2b1-454e-ada5-10ada9a49e76"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cfg/training/yolov7_garbage-tiny.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the model\n",
        "Finally, we can run the model.\n",
        "\n",
        "Letâ€™s go over the important flags in the below command:\n",
        "\n",
        "- device: The GPU number (ID) to use for training. As we have only one GPU, so, it is 0.\n",
        "- data: This accepts the path to the dataset YAML file.\n",
        "- img: By default, the images will be resized to 640Ã—640 resolution before being fed to the network. Still, we are providing the image size here.\n",
        "- cfg: This is the path to the model configuration file which is needed for loading the model architecture which we created just before.\n",
        "- weights: This flag accepts the path to the pretrained model.\n",
        "- name: All the training, validation, and test results are saved in subdirectories inside the runs directory by default. We can provide the name of these subdirectories by specifying a string name from this flag.\n",
        "- hyp: All the models in the YOLOv7 family have a different set of parameters and hyperparameters. These include the learning rate, the augmentation techniques, and also the intensity of the augmentations among many other hyperparameters. All these are defined in their hyperparameter files (YAML files) in the yolov7/data directory. Here, we specify the path to the appropriate YOLOv7-tiny model hyperparameter file.\n",
        "\n",
        "The other flags define the number of epochs to train for, the batch size, and the number of workers. You can set these according to the hardware that you are using. Here, we are training the model for 100 epochs.\n",
        "\n"
      ],
      "metadata": {
        "id": "B2XKYdLiQhMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --epochs 100 --workers 4 --device 0 --batch-size 32 \\\n",
        "--data garbage_sub/data.yaml --img 640 640 --cfg cfg/training/yolov7_garbage-tiny.yaml \\\n",
        "--weights 'yolov7-tiny.pt' --name yolov7_tiny_garbage_fixed_res --hyp data/hyp.scratch.tiny.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B3CyWAmxBuU",
        "outputId": "58f665af-be8c-4b88-e725-c2affba93bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-07 10:30:04.080372: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-07 10:30:04.080424: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-07 10:30:04.080457: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-07 10:30:04.087949: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-07 10:30:05.123048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "YOLOR ðŸš€ v0.1-128-ga207844 torch 2.1.0+cu118 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Namespace(weights='yolov7-tiny.pt', cfg='cfg/training/yolov7_garbage-tiny.yaml', data='garbage_sub/data.yaml', hyp='data/hyp.scratch.tiny.yaml', epochs=100, batch_size=32, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=4, project='runs/train', entity=None, name='yolov7_tiny_garbage_fixed_res', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/yolov7_tiny_garbage_fixed_res2', total_batch_size=32)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.05, copy_paste=0.0, paste_in=0.05, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  2                -1  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  3                -2  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  4                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  5                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  6  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            "  7                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  8                -1  1         0  models.common.MP                        []                            \n",
            "  9                -1  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 10                -2  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 11                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 12                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 13  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 15                -1  1         0  models.common.MP                        []                            \n",
            " 16                -1  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 17                -2  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 20  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 22                -1  1         0  models.common.MP                        []                            \n",
            " 23                -1  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 24                -2  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 25                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 26                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 27  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 28                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 29                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 30                -2  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 31                -1  1         0  models.common.SP                        [5]                           \n",
            " 32                -2  1         0  models.common.SP                        [9]                           \n",
            " 33                -3  1         0  models.common.SP                        [13]                          \n",
            " 34  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 35                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 36          [-1, -7]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 38                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 39                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 40                21  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 41          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 42                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 43                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 44                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 45                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 46  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 47                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 48                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 49                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 50                14  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 51          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 52                -1  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 53                -2  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 54                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 55                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 56  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 57                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 58                -1  1     73984  models.common.Conv                      [64, 128, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 59          [-1, 47]  1         0  models.common.Concat                    [1]                           \n",
            " 60                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 61                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 62                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 63                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 64  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 65                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 66                -1  1    295424  models.common.Conv                      [128, 256, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 67          [-1, 37]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 69                -2  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 70                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 71                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 72  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 73                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 74                57  1     73984  models.common.Conv                      [64, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 75                65  1    295424  models.common.Conv                      [128, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 76                73  1   1180672  models.common.Conv                      [256, 512, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 77      [74, 75, 76]  1     17132  models.yolo.IDetect                     [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 263 layers, 6014988 parameters, 6014988 gradients, 13.2 GFLOPS\n",
            "\n",
            "Transferred 330/344 items from yolov7-tiny.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 58 .bias, 58 conv.weight, 61 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'garbage_sub/train/labels' images and labels... 289 found, 0 missing, 14 empty, 0 corrupted: 100% 289/289 [00:00<00:00, 3257.76it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: garbage_sub/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'garbage_sub/valid/labels' images and labels... 28 found, 0 missing, 3 empty, 0 corrupted: 100% 28/28 [00:00<00:00, 924.01it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: garbage_sub/valid/labels.cache\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.44, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/yolov7_tiny_garbage_fixed_res2\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/99    0.411G   0.06127   0.02787         0   0.08914         4       640: 100% 10/10 [00:25<00:00,  2.60s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:02<00:00,  2.34s/it]\n",
            "                 all          28          28      0.0228      0.0714     0.00714     0.00136\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/99     5.09G      0.06   0.01768         0   0.07768         4       640: 100% 10/10 [00:09<00:00,  1.07it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.23it/s]\n",
            "                 all          28          28      0.0957        0.25      0.0468      0.0127\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/99     5.09G   0.05701   0.01353         0   0.07054         2       640: 100% 10/10 [00:10<00:00,  1.09s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.20it/s]\n",
            "                 all          28          28       0.318        0.25       0.132      0.0564\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/99     5.09G    0.0515   0.01333         0   0.06483         4       640: 100% 10/10 [00:11<00:00,  1.12s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.49it/s]\n",
            "                 all          28          28        0.36        0.25       0.198      0.0893\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/99     5.09G   0.04898   0.01204         0   0.06102         2       640: 100% 10/10 [00:12<00:00,  1.23s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.29it/s]\n",
            "                 all          28          28       0.492       0.286       0.271        0.12\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/99     5.09G   0.04796    0.0115         0   0.05946         2       640: 100% 10/10 [00:12<00:00,  1.27s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.59it/s]\n",
            "                 all          28          28       0.386       0.427       0.288       0.146\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/99     5.09G   0.04728   0.01104         0   0.05832         3       640: 100% 10/10 [00:12<00:00,  1.26s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.90it/s]\n",
            "                 all          28          28       0.413       0.429       0.441       0.209\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/99     5.09G   0.04218   0.01139         0   0.05357         1       640: 100% 10/10 [00:12<00:00,  1.26s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.69it/s]\n",
            "                 all          28          28       0.456       0.569       0.423       0.186\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/99     5.09G    0.0412   0.01127         0   0.05247         2       640: 100% 10/10 [00:11<00:00,  1.16s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.71it/s]\n",
            "                 all          28          28       0.375       0.714       0.409       0.195\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/99     5.09G   0.03878   0.01227         0   0.05105         4       640: 100% 10/10 [00:12<00:00,  1.22s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.91it/s]\n",
            "                 all          28          28       0.384       0.607       0.413       0.195\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/99     5.09G   0.04031   0.01183         0   0.05215         1       640: 100% 10/10 [00:12<00:00,  1.29s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.89it/s]\n",
            "                 all          28          28       0.419       0.464       0.352       0.134\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/99     5.09G   0.03285   0.01107         0   0.04392         3       640: 100% 10/10 [00:12<00:00,  1.22s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.80it/s]\n",
            "                 all          28          28       0.615       0.571         0.5       0.161\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/99     5.09G   0.04331   0.01098         0   0.05429         2       640: 100% 10/10 [00:13<00:00,  1.39s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.58it/s]\n",
            "                 all          28          28       0.331       0.567       0.356       0.159\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/99     5.09G   0.03708   0.01155         0   0.04863         4       640: 100% 10/10 [00:11<00:00,  1.18s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.73it/s]\n",
            "                 all          28          28       0.618       0.357       0.391       0.154\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/99     5.09G    0.0387     0.013         0   0.05169         6       640: 100% 10/10 [00:12<00:00,  1.28s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.88it/s]\n",
            "                 all          28          28       0.485       0.639       0.451        0.19\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/99     5.09G    0.0409   0.01062         0   0.05152         2       640: 100% 10/10 [00:12<00:00,  1.22s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.88it/s]\n",
            "                 all          28          28       0.411       0.499       0.341       0.147\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "  0% 0/10 [00:00<?, ?it/s]"
          ]
        }
      ]
    }
  ]
}