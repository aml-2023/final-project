{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Object Detection with YOLO"
      ],
      "metadata": {
        "id": "_3T7hgTQlEVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "import os\n",
        "import glob as glob\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "2uHPOZ7LCIXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the files in current directory & delete them if neccessary\n",
        "!ls\n",
        "\n",
        "# remove directories and files\n",
        "!rm -rf ./garbage\n",
        "!rm -rf ./garbage_sub\n",
        "!rm -rf ./runs\n",
        "\n",
        "!rm -rf ./yolov7\n",
        "\n",
        "!rm -rf ./yolov8n.pt\n",
        "\n",
        "!rm -rf ./fetch_data.sh\n",
        "\n",
        "!rm -rf ./roboflow.zip\n",
        "\n",
        "!rm -rf ./requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDHx2vs9kq5N",
        "outputId": "ab27b41d-3d1b-44f0-d3e8-ea4f01473149"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "IH4_truCkZKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJfIUpOtTRpo",
        "outputId": "bf2f8bf7-9e47-4df7-e2a6-f281d6cf1cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLO v7"
      ],
      "metadata": {
        "id": "ATJpz3UAZZgZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the YOLOv7 GitHub Repository & ENTER IT (we want to download the data inside this directory)"
      ],
      "metadata": {
        "id": "sDb6679sq4JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('yolov7'):\n",
        "    !git clone https://github.com/WongKinYiu/yolov7.git\n",
        "\n",
        "%cd yolov7\n",
        "\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zao8eUVVsQht",
        "outputId": "8604bb53-2baa-473f-d082-efe4d8cec3b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1197, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 1197 (delta 2), reused 3 (delta 1), pack-reused 1191\u001b[K\n",
            "Receiving objects: 100% (1197/1197), 74.23 MiB | 33.74 MiB/s, done.\n",
            "Resolving deltas: 100% (517/517), done.\n",
            "/content/yolov7\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.11.4)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.66.1)\n",
            "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (3.20.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (2.14.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.12.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (7.34.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (5.9.5)\n",
            "Collecting thop (from -r requirements.txt (line 36))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.59.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.5.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.0.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2023.3.post1)\n",
            "Collecting jedi>=0.16 (from ipython->-r requirements.txt (line 34))\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.9.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 34)) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 34)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n",
            "Installing collected packages: jedi, thop\n",
            "Successfully installed jedi-0.19.1 thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "OENF_yWiRncT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O requirements.txt https://raw.githubusercontent.com/aml-2023/final-project/yolo/requirements.txt\n",
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWvDsbjPCMMQ",
        "outputId": "8b43cc81-b77a-4377-ce21-b6dfb0b8682e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-09 15:44:48--  https://raw.githubusercontent.com/aml-2023/final-project/yolo/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37 [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "\rrequirements.txt      0%[                    ]       0  --.-KB/s               \rrequirements.txt    100%[===================>]      37  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-09 15:44:48 (1.13 MB/s) - ‘requirements.txt’ saved [37/37]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the data into the yolov7 directory\n",
        "- specify the data type \"yolo\""
      ],
      "metadata": {
        "id": "zTOsan7oSCtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O fetch_data.sh https://raw.githubusercontent.com/aml-2023/final-project/main/fetch_data.sh\n",
        "!bash fetch_data.sh --type yolo --output garbage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGa4PQ5SB7Kh",
        "outputId": "9d0f6b43-826e-4ba2-a2ba-37823a6b9d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-09 16:01:09--  https://raw.githubusercontent.com/aml-2023/final-project/main/fetch_data.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1222 (1.2K) [text/plain]\n",
            "Saving to: ‘fetch_data.sh’\n",
            "\n",
            "\rfetch_data.sh         0%[                    ]       0  --.-KB/s               \rfetch_data.sh       100%[===================>]   1.19K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-09 16:01:09 (95.4 MB/s) - ‘fetch_data.sh’ saved [1222/1222]\n",
            "\n",
            "Downloading data\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   894  100   894    0     0    628      0  0:00:01  0:00:01 --:--:--   628\n",
            "100  274M  100  274M    0     0  85.1M      0  0:00:03  0:00:03 --:--:--  181M\n",
            "Data downloaded and extracted into garbage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### YAML File\n",
        "- Crete the Data YAML File\n",
        "- We already have it so we overwrite it"
      ],
      "metadata": {
        "id": "Wi2OWRkAcGi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile garbage/data.yaml\n",
        "train: garbage/train\n",
        "val: garbage/valid\n",
        "test: garbage/test\n",
        "\n",
        "# Classes\n",
        "nc: 1  # number of classes\n",
        "names: ['garbage']  # class names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SwSyGpjsw7W",
        "outputId": "d5b51b0d-68fd-4edc-faf1-4d10a3dafa40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting garbage/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subset the data"
      ],
      "metadata": {
        "id": "zXHY4UM2TbA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pathlib\n",
        "\n",
        "def label_path_from_image_path(image_path: str, base_path):\n",
        "    \"\"\"Gets the YOLO label path from the image path.\"\"\"\n",
        "    label = image_path.split(\"/\")[-1]\n",
        "    label = label[:-3] + \"txt\"\n",
        "    label = os.path.join(base_path, label)\n",
        "    return label\n",
        "\n",
        "\n",
        "def get_image_label_path_pair(base_path: str, split_folder: str):\n",
        "    \"\"\"Gets all the image and label path pairs for a specific base path and the split folder, e.g. garbage and test.\"\"\"\n",
        "    img_path = os.path.join(base_path, split_folder, \"images\")\n",
        "    labels_path = os.path.join(base_path, split_folder, \"labels\")\n",
        "\n",
        "    pairs = []\n",
        "    for image_name in glob(f\"{img_path}/*.jpg\"):\n",
        "        label = label_path_from_image_path(image_name, labels_path)\n",
        "        pairs.append((image_name, label))\n",
        "\n",
        "    return pairs\n",
        "\n",
        "\n",
        "def subset_split_folder(yolo_root_dir: str, percentage: float, split_folder: str, out_dir: str):\n",
        "    \"\"\"Subsets a split folder (train, test, valid) and copies the subset to a new directory.\"\"\"\n",
        "    pairs = get_image_label_path_pair(yolo_root_dir, split_folder)\n",
        "    subset_len = int(len(pairs) * percentage)\n",
        "    subset_idx = np.random.randint(low=0, high=len(pairs), size=subset_len)\n",
        "\n",
        "    subset_pairs = [pairs[i] for i in subset_idx]\n",
        "\n",
        "    out_dir_img = os.path.join(out_dir, split_folder, \"images\")\n",
        "    out_dir_labels = os.path.join(out_dir, split_folder, \"labels\")\n",
        "\n",
        "    pathlib.Path(out_dir_img).mkdir(parents=True, exist_ok=True)\n",
        "    pathlib.Path(out_dir_labels).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for img, label in subset_pairs:\n",
        "        dest_img_path = os.path.join(out_dir_img, img.split(\"/\")[-1])\n",
        "        dest_label_path = os.path.join(out_dir_labels, label.split(\"/\")[-1])\n",
        "\n",
        "        shutil.copy(img, dest_img_path)\n",
        "        shutil.copy(label, dest_label_path)\n",
        "\n",
        "def subset_yolo_data(yolo_root_dir: str, percentage: float, out_dir: str):\n",
        "    \"\"\"Subsets the YOLO dataset by taking a percentage of the original data and moving it into a new directory.\n",
        "\n",
        "    :arg\n",
        "        yolo_root_dir (str): the root directory where the yolo data is.\n",
        "        percentage (float): the percentage of images to keep.\n",
        "        out_dir (str): the output directory, will be created if it does not exist.\n",
        "    \"\"\"\n",
        "    subset_split_folder(yolo_root_dir, percentage, \"train\", out_dir)\n",
        "    subset_split_folder(yolo_root_dir, percentage, \"test\", out_dir)\n",
        "    subset_split_folder(yolo_root_dir, percentage, \"valid\", out_dir)\n",
        "\n",
        "    other_files = [\"README.dataset.txt\", \"README.roboflow.txt\", \"data.yaml\"]\n",
        "\n",
        "    for file in other_files:\n",
        "        old_path = os.path.join(yolo_root_dir, file)\n",
        "        new_path = os.path.join(out_dir, file)\n",
        "        shutil.copy(old_path, new_path)"
      ],
      "metadata": {
        "id": "q4OCtrV1ORAi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subset_yolo_data(\"garbage\", 0.20, \"garbage_sub\")"
      ],
      "metadata": {
        "id": "u-241pooQq56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overwrite again the .yaml file in the newly created subset garbage folder."
      ],
      "metadata": {
        "id": "zyVOnQWDQurH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile garbage_sub/data.yaml\n",
        "train: garbage_sub/train\n",
        "val: garbage_sub/valid\n",
        "test: garbage_sub/test\n",
        "\n",
        "# Classes\n",
        "nc: 1  # number of classes\n",
        "names: ['garbage']  # class names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6Ylob5JQuhK",
        "outputId": "ed902c29-6e96-42b9-9a9b-8443dbd10f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting garbage_sub/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the YOLO Tiny model weights."
      ],
      "metadata": {
        "id": "YgnfU9XRcXu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGVwOiiTsw42",
        "outputId": "994b8047-0abc-43e5-9630-df545a840457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-09 15:37:08--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/ba7d01ee-125a-4134-8864-fa1abcbf94d5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231209%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231209T153708Z&X-Amz-Expires=300&X-Amz-Signature=c8cd85f5d25df6e8b9de5c7c411922a4fdddaa87356fe4d8c6a7b49d63b12cef&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7-tiny.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-12-09 15:37:08--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/ba7d01ee-125a-4134-8864-fa1abcbf94d5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231209%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231209T153708Z&X-Amz-Expires=300&X-Amz-Signature=c8cd85f5d25df6e8b9de5c7c411922a4fdddaa87356fe4d8c6a7b49d63b12cef&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7-tiny.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12639769 (12M) [application/octet-stream]\n",
            "Saving to: ‘yolov7-tiny.pt’\n",
            "\n",
            "yolov7-tiny.pt      100%[===================>]  12.05M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-12-09 15:37:08 (92.1 MB/s) - ‘yolov7-tiny.pt’ saved [12639769/12639769]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cfg/training/yolov7_garbage-tiny.yaml\n",
        "\n",
        "# parameters\n",
        "nc: 1  # number of classes\n",
        "depth_multiple: 1.0  # model depth multiple\n",
        "width_multiple: 1.0  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# yolov7-tiny backbone\n",
        "backbone:\n",
        "  # [from, number, module, args] c2, k=1, s=1, p=None, g=1, act=True\n",
        "  [[-1, 1, Conv, [32, 3, 2, None, 1, nn.LeakyReLU(0.1)]],  # 0-P1/2\n",
        "\n",
        "   [-1, 1, Conv, [64, 3, 2, None, 1, nn.LeakyReLU(0.1)]],  # 1-P2/4\n",
        "\n",
        "   [-1, 1, Conv, [32, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-2, 1, Conv, [32, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, Conv, [32, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, Conv, [32, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "   [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 7\n",
        "\n",
        "   [-1, 1, MP, []],  # 8-P3/8\n",
        "   [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-2, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "   [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 14\n",
        "\n",
        "   [-1, 1, MP, []],  # 15-P4/16\n",
        "   [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-2, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, Conv, [128, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, Conv, [128, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "   [-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 21\n",
        "\n",
        "   [-1, 1, MP, []],  # 22-P5/32\n",
        "   [-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-2, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, Conv, [256, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, Conv, [256, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "   [-1, 1, Conv, [512, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 28\n",
        "  ]\n",
        "\n",
        "# yolov7-tiny head\n",
        "head:\n",
        "  [[-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-2, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, SP, [5]],\n",
        "   [-2, 1, SP, [9]],\n",
        "   [-3, 1, SP, [13]],\n",
        "   [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "   [-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [[-1, -7], 1, Concat, [1]],\n",
        "   [-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 37\n",
        "\n",
        "   [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [21, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]], # route backbone P4\n",
        "   [[-1, -2], 1, Concat, [1]],\n",
        "\n",
        "   [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-2, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "   [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 47\n",
        "\n",
        "   [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [14, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]], # route backbone P3\n",
        "   [[-1, -2], 1, Concat, [1]],\n",
        "\n",
        "   [-1, 1, Conv, [32, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-2, 1, Conv, [32, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, Conv, [32, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, Conv, [32, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "   [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 57\n",
        "\n",
        "   [-1, 1, Conv, [128, 3, 2, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [[-1, 47], 1, Concat, [1]],\n",
        "\n",
        "   [-1, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-2, 1, Conv, [64, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, Conv, [64, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "   [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 65\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [[-1, 37], 1, Concat, [1]],\n",
        "\n",
        "   [-1, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-2, 1, Conv, [128, 1, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, Conv, [128, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [-1, 1, Conv, [128, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [[-1, -2, -3, -4], 1, Concat, [1]],\n",
        "   [-1, 1, Conv, [256, 1, 1, None, 1, nn.LeakyReLU(0.1)]],  # 73\n",
        "\n",
        "   [57, 1, Conv, [128, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [65, 1, Conv, [256, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "   [73, 1, Conv, [512, 3, 1, None, 1, nn.LeakyReLU(0.1)]],\n",
        "\n",
        "   [[74,75,76], 1, IDetect, [nc, anchors]],   # Detect(P3, P4, P5)\n",
        "  ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSUc4RHBsw2f",
        "outputId": "7abb8675-140b-4648-97e4-11751b2a75a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cfg/training/yolov7_garbage-tiny.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model\n",
        "- only on a subset of the data\n"
      ],
      "metadata": {
        "id": "TCU3r2Fecjd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --epochs 100 --workers 4 --device 0 --batch-size 32 \\\n",
        "--data garbage_sub/data.yaml --img 640 640 --cfg cfg/training/yolov7_garbage-tiny.yaml \\\n",
        "--weights 'yolov7-tiny.pt' --name yolov7_tiny_garbage_fixed_res --hyp data/hyp.scratch.tiny.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N7JRqUpswz2",
        "outputId": "9bd3b329-5cd0-4a71-d9c9-55f4e713d42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-08 22:59:42.127783: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-08 22:59:42.127840: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-08 22:59:42.127876: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-08 22:59:42.135832: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-08 22:59:43.182257: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "YOLOR 🚀 v0.1-128-ga207844 torch 2.1.0+cu118 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Namespace(weights='yolov7-tiny.pt', cfg='cfg/training/yolov7_garbage-tiny.yaml', data='garbage_sub/data.yaml', hyp='data/hyp.scratch.tiny.yaml', epochs=100, batch_size=32, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=4, project='runs/train', entity=None, name='yolov7_tiny_garbage_fixed_res', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/yolov7_tiny_garbage_fixed_res', total_batch_size=32)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.05, copy_paste=0.0, paste_in=0.05, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  2                -1  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  3                -2  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  4                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  5                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  6  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            "  7                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  8                -1  1         0  models.common.MP                        []                            \n",
            "  9                -1  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 10                -2  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 11                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 12                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 13  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 15                -1  1         0  models.common.MP                        []                            \n",
            " 16                -1  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 17                -2  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 20  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 22                -1  1         0  models.common.MP                        []                            \n",
            " 23                -1  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 24                -2  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 25                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 26                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 27  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 28                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 29                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 30                -2  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 31                -1  1         0  models.common.SP                        [5]                           \n",
            " 32                -2  1         0  models.common.SP                        [9]                           \n",
            " 33                -3  1         0  models.common.SP                        [13]                          \n",
            " 34  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 35                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 36          [-1, -7]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 38                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 39                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 40                21  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 41          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 42                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 43                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 44                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 45                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 46  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 47                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 48                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 49                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 50                14  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 51          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 52                -1  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 53                -2  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 54                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 55                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 56  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 57                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 58                -1  1     73984  models.common.Conv                      [64, 128, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 59          [-1, 47]  1         0  models.common.Concat                    [1]                           \n",
            " 60                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 61                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 62                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 63                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 64  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 65                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 66                -1  1    295424  models.common.Conv                      [128, 256, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 67          [-1, 37]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 69                -2  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 70                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 71                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 72  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 73                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 74                57  1     73984  models.common.Conv                      [64, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 75                65  1    295424  models.common.Conv                      [128, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 76                73  1   1180672  models.common.Conv                      [256, 512, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 77      [74, 75, 76]  1     17132  models.yolo.IDetect                     [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 263 layers, 6014988 parameters, 6014988 gradients, 13.2 GFLOPS\n",
            "\n",
            "Transferred 330/344 items from yolov7-tiny.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 58 .bias, 58 conv.weight, 61 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'garbage_sub/train/labels' images and labels... 555 found, 0 missing, 31 empty, 0 corrupted: 100% 555/555 [00:00<00:00, 2229.70it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: garbage_sub/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'garbage_sub/valid/labels' images and labels... 54 found, 0 missing, 4 empty, 0 corrupted: 100% 54/54 [00:00<00:00, 740.79it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: garbage_sub/valid/labels.cache\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.38, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/yolov7_tiny_garbage_fixed_res\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/99    0.776G   0.06271   0.02348         0   0.08619        32       640: 100% 18/18 [00:40<00:00,  2.26s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:03<00:00,  3.06s/it]\n",
            "                 all          54          57       0.017       0.263      0.0125     0.00236\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/99     4.74G   0.05841   0.01358         0   0.07199        25       640: 100% 18/18 [00:25<00:00,  1.42s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.00s/it]\n",
            "                 all          54          57       0.147       0.175      0.0841      0.0347\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/99     5.72G    0.0531   0.01207         0   0.06517        29       640: 100% 18/18 [00:26<00:00,  1.45s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.26it/s]\n",
            "                 all          54          57       0.381       0.228       0.183      0.0679\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/99     5.72G   0.05041   0.01106         0   0.06147        33       640: 100% 18/18 [00:26<00:00,  1.46s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.03s/it]\n",
            "                 all          54          57       0.499       0.333       0.299      0.0981\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/99     5.72G    0.0473   0.01149         0   0.05879        32       640: 100% 18/18 [00:29<00:00,  1.65s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.24it/s]\n",
            "                 all          54          57       0.471       0.456       0.447       0.181\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/99     5.72G   0.03834   0.01119         0   0.04953        18       640: 100% 18/18 [00:24<00:00,  1.38s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.02s/it]\n",
            "                 all          54          57       0.678       0.421       0.486        0.15\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/99     5.72G   0.04441   0.01006         0   0.05446        30       640: 100% 18/18 [00:24<00:00,  1.38s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.34it/s]\n",
            "                 all          54          57         0.5       0.421       0.401       0.162\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/99     5.72G   0.05477   0.01084         0   0.06561        27       640: 100% 18/18 [00:26<00:00,  1.46s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.34it/s]\n",
            "                 all          54          57       0.211       0.491       0.165      0.0363\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/99     5.72G   0.04281    0.0107         0   0.05351        29       640: 100% 18/18 [00:26<00:00,  1.47s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.43it/s]\n",
            "                 all          54          57       0.293       0.351       0.234      0.0639\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/99     5.72G   0.04796   0.01133         0   0.05929        24       640: 100% 18/18 [00:26<00:00,  1.47s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.04it/s]\n",
            "                 all          54          57       0.269       0.401       0.207      0.0627\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/99     5.72G   0.05111   0.01145         0   0.06256        28       640: 100% 18/18 [00:24<00:00,  1.35s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.12s/it]\n",
            "                 all          54          57       0.525       0.368       0.314       0.136\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/99     5.72G   0.04414   0.01125         0   0.05539        26       640: 100% 18/18 [00:28<00:00,  1.58s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.04it/s]\n",
            "                 all          54          57       0.164      0.0877      0.0409     0.00798\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/99     5.72G   0.04368   0.01144         0   0.05512        31       640: 100% 18/18 [00:25<00:00,  1.43s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.35it/s]\n",
            "                 all          54          57      0.0732       0.175      0.0202     0.00377\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/99     5.72G   0.04593   0.01173         0   0.05766        29       640: 100% 18/18 [00:27<00:00,  1.52s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.39it/s]\n",
            "                 all          54          57       0.225       0.281       0.146      0.0319\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/99     5.72G   0.04092   0.01324         0   0.05415        23       640: 100% 18/18 [00:28<00:00,  1.59s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.35it/s]\n",
            "                 all          54          57      0.0448        0.14      0.0261     0.00495\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/99     5.72G   0.05151   0.01261         0   0.06412        28       640: 100% 18/18 [00:26<00:00,  1.49s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.49it/s]\n",
            "                 all          54          57       0.195       0.211       0.116      0.0358\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/99     5.72G   0.06176   0.01326         0   0.07502        22       640: 100% 18/18 [00:25<00:00,  1.40s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.01s/it]\n",
            "                 all          54          57       0.118       0.404      0.0873       0.015\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/99     5.72G   0.05141   0.01374         0   0.06514        29       640: 100% 18/18 [00:25<00:00,  1.42s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.13it/s]\n",
            "                 all          54          57      0.0735       0.246       0.044     0.00737\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/99     5.72G   0.05273   0.01353         0   0.06625        32       640: 100% 18/18 [00:29<00:00,  1.62s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.36it/s]\n",
            "                 all          54          57       0.171       0.105      0.0575     0.00801\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/99     5.72G   0.04015   0.01329         0   0.05345        33       640: 100% 18/18 [00:27<00:00,  1.50s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.39it/s]\n",
            "                 all          54          57       0.183       0.365       0.163      0.0315\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/99     5.72G   0.05172    0.0139         0   0.06562        27       640: 100% 18/18 [00:27<00:00,  1.52s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.46it/s]\n",
            "                 all          54          57      0.0163       0.123      0.0107     0.00191\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/99     5.72G   0.04823   0.01389         0   0.06213        28       640: 100% 18/18 [00:27<00:00,  1.51s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.62it/s]\n",
            "                 all          54          57      0.0127      0.0351     0.00306    0.000555\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/99     5.72G   0.05478   0.01411         0   0.06889        41       640: 100% 18/18 [00:26<00:00,  1.48s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.08s/it]\n",
            "                 all          54          57      0.0248       0.105     0.00543    0.000999\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/99     5.72G    0.0499   0.01513         0   0.06502        30       640: 100% 18/18 [00:25<00:00,  1.42s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.07s/it]\n",
            "                 all          54          57     0.00591       0.316     0.00423    0.000684\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/99     5.72G   0.03979   0.01404         0   0.05383        24       640: 100% 18/18 [00:25<00:00,  1.43s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.62it/s]\n",
            "                 all          54          57      0.0414      0.0351     0.00667     0.00115\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/99     5.72G   0.04693   0.01444         0   0.06137        35       640: 100% 18/18 [00:29<00:00,  1.62s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.35s/it]\n",
            "                 all          54          57      0.0572      0.0877      0.0227     0.00499\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/99     5.72G    0.0449   0.01363         0   0.05852        21       640: 100% 18/18 [00:26<00:00,  1.49s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.43it/s]\n",
            "                 all          54          57      0.0141       0.509      0.0111     0.00291\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/99     5.73G   0.03833   0.01409         0   0.05242        27       640: 100% 18/18 [00:26<00:00,  1.48s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.43it/s]\n",
            "                 all          54          57      0.0462       0.439      0.0342     0.00813\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/99     5.73G   0.04252   0.01349         0   0.05602        30       640: 100% 18/18 [00:26<00:00,  1.45s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.07it/s]\n",
            "                 all          54          57      0.0207      0.0877     0.00778     0.00151\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/99     5.73G   0.05103   0.01415         0   0.06519        23       640: 100% 18/18 [00:25<00:00,  1.41s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.29it/s]\n",
            "                 all          54          57      0.0338      0.0877      0.0147     0.00312\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/99     5.73G   0.04456    0.0147         0   0.05926        39       640: 100% 18/18 [00:27<00:00,  1.52s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.48it/s]\n",
            "                 all          54          57      0.0414      0.0351      0.0105     0.00167\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/99     5.73G   0.04683   0.01478         0   0.06161        28       640: 100% 18/18 [00:27<00:00,  1.51s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.41it/s]\n",
            "                 all          54          57     0.00481       0.123     0.00147    0.000303\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/99     5.73G   0.04067   0.01387         0   0.05454        31       640: 100% 18/18 [00:28<00:00,  1.60s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.47it/s]\n",
            "                 all          54          57      0.0134       0.193     0.00868     0.00147\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     33/99     5.73G    0.0434     0.014         0    0.0574        23       640: 100% 18/18 [00:27<00:00,  1.50s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.49it/s]\n",
            "                 all          54          57      0.0219       0.105      0.0148     0.00287\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     34/99     5.73G   0.04289   0.01449         0   0.05738        37       640: 100% 18/18 [00:24<00:00,  1.37s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 1/1 [00:01<00:00,  1.03s/it]\n",
            "                 all          54          57      0.0839      0.0351       0.031     0.00744\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     35/99     5.73G    0.0448   0.01498         0   0.05977        77       640:  44% 8/18 [07:35<09:28, 56.90s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov7/train.py\", line 616, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"/content/yolov7/train.py\", line 336, in train\n",
            "    for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1182, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/content/yolov7/utils/datasets.py\", line 110, in __iter__\n",
            "    yield next(self.iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1328, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1284, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1132, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/queue.py\", line 180, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 324, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n",
            "Exception ignored in atexit callback: <function dump_compile_times at 0x7e364ad72560>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 247, in dump_compile_times\n",
            "    log.info(compile_times(repr=\"str\", aggregate=True))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 234, in compile_times\n",
            "    out += tabulate(rows, headers=(\"Function\", \"Runtimes (s)\"))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 86, in tabulate\n",
            "    import tabulate\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py\", line 714, in <module>\n",
            "    _multiline_codes = re.compile(r\"\\r|\\n|\\r\\n\")\n",
            "  File \"/usr/lib/python3.10/re.py\", line 251, in compile\n",
            "    return _compile(pattern, flags)\n",
            "  File \"/usr/lib/python3.10/re.py\", line 303, in _compile\n",
            "    p = sre_compile.compile(pattern, flags)\n",
            "  File \"/usr/lib/python3.10/sre_compile.py\", line 794, in compile\n",
            "    if flags & SRE_FLAG_DEBUG:\n",
            "KeyboardInterrupt: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "6GBlUCOSsSoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/yolov7_tiny_garbage_fixed_res/weights/best.pt --task test --data garbage/data.yaml"
      ],
      "metadata": {
        "id": "EBUL2GZBswrN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41db6ac7-7fec-481c-8e5b-4e72b29b0c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['runs/train/yolov7_tiny_garbage_fixed_res/weights/best.pt'], data='garbage/data.yaml', batch_size=32, img_size=640, conf_thres=0.001, iou_thres=0.65, task='test', device='', single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project='runs/test', name='exp', exist_ok=False, no_trace=False, v5_metric=False)\n",
            "YOLOR 🚀 v0.1-128-ga207844 torch 2.1.0+cu118 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 208 layers, 6007596 parameters, 0 gradients, 13.0 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'garbage/test/labels' images and labels... 201 found, 0 missing, 14 empty, 0 corrupted: 100% 201/201 [00:00<00:00, 585.60it/s]\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: garbage/test/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.47it/s]\n",
            "                 all         201         218        0.54        0.61       0.498       0.211\n",
            "Speed: 8.4/2.4/10.8 ms inference/NMS/total per 640x640 image at batch-size 32\n",
            "Results saved to runs/test/exp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dMAV7Os0soYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLO v8\n",
        "\n",
        "https://github.com/ultralytics/ultralytics"
      ],
      "metadata": {
        "id": "Dltx5TqqReZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why Choose Ultralytics YOLO for Training?\n",
        "\n",
        "Here are some compelling reasons to opt for YOLOv8's Train mode:\n",
        "\n",
        "- Efficiency: Make the most out of your hardware, whether you're on a single-GPU setup or scaling across multiple GPUs.\n",
        "- Versatility: Train on custom datasets in addition to readily available ones like COCO, VOC, and ImageNet.\n",
        "- User-Friendly: Simple yet powerful CLI and Python interfaces for a straightforward training experience.\n",
        "- Hyperparameter Flexibility: A broad range of customizable hyperparameters to fine-tune model performance."
      ],
      "metadata": {
        "id": "cFh_6s8qeGs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the ultralytics package\n",
        "!pip install ultralytics -qq"
      ],
      "metadata": {
        "id": "uQKWYdRKyKb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f22da0d1-fc36-4455-cc18-4aaa049a70ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/660.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/660.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m450.6/660.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.4/660.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "D6C5EDgQUBK9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA\n",
        "!wget -O fetch_data.sh https://raw.githubusercontent.com/aml-2023/final-project/main/fetch_data.sh\n",
        "!bash fetch_data.sh --type yolo --output garbage\n",
        "\n",
        "# SUBSET\n",
        "subset_yolo_data(\"garbage\", 0.10, \"garbage_sub\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMMta3usT_8D",
        "outputId": "03370345-a255-40ed-caa1-52b3f15db63d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-11 14:19:42--  https://raw.githubusercontent.com/aml-2023/final-project/main/fetch_data.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1222 (1.2K) [text/plain]\n",
            "Saving to: ‘fetch_data.sh’\n",
            "\n",
            "fetch_data.sh       100%[===================>]   1.19K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-11 14:19:42 (53.1 MB/s) - ‘fetch_data.sh’ saved [1222/1222]\n",
            "\n",
            "Downloading data\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   894  100   894    0     0    372      0  0:00:02  0:00:02 --:--:--   372\n",
            "100  274M  100  274M    0     0  49.0M      0  0:00:05  0:00:05 --:--:--  105M\n",
            "Data downloaded and extracted into garbage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train mode is used for training a YOLOv8 model on a custom dataset. In this mode, the model is trained using the specified dataset and hyperparameters. The training process involves optimizing the model's parameters so that it can accurately predict the classes and locations of objects in an image (in this case the garbage)"
      ],
      "metadata": {
        "id": "D-7iqH2IWPXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model yolo v8"
      ],
      "metadata": {
        "id": "cA7aq6r8nKB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a model\n",
        "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "model.train(data=\"/content/garbage_sub/data.yaml\", epochs=50)  # train the model\n",
        "metrics = model.val()  # evaluate model performance on the validation set"
      ],
      "metadata": {
        "id": "DH7D8pUOyKah",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d714ffe3-390e-4640-ad9f-cda299659992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 122MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.225 🚀 Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/garbage_sub/data.yaml, epochs=75, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/garbage_sub/train/labels... 1083 images, 70 backgrounds, 0 corrupt: 100%|██████████| 1083/1083 [00:00<00:00, 1832.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/garbage_sub/train/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 2, len(boxes) = 1149. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/garbage_sub/valid/labels... 110 images, 4 backgrounds, 0 corrupt: 100%|██████████| 110/110 [00:00<00:00, 2438.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/garbage_sub/valid/labels.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 75 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/75         0G      1.653      2.766      1.897         55        640:   1%|▏         | 1/68 [00:25<28:31, 25.54s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-4b96ff5c69a1>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Use the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/garbage_sub/data.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# evaluate model performance on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;31m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resuming Interrupted Trainings\n",
        "\n",
        "resume=True -- the train function will continue training from where it left off, using the state stored in the 'path/to/last.pt' file."
      ],
      "metadata": {
        "id": "MsCLzi0Aelv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a model\n",
        "model = YOLO('path/to/last.pt')  # load a partially trained model\n",
        "\n",
        "# Resume training\n",
        "results = model.train(resume=True)"
      ],
      "metadata": {
        "id": "8GFADtiFelL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensorboard"
      ],
      "metadata": {
        "id": "znl-oqROjfkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_ext tensorboard\n",
        "tensorboard --logdir ultralytics/runs  # replace with 'runs' directory"
      ],
      "metadata": {
        "id": "lHpMSwKbfYdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results1 = model(\"/content/garbage_sub/test/images/1c68ac06-6798-11e5-8c9e-40f2e96c8ad8_jpg.rf.ee444cd59bfe8d301877ff4e4c74ea7c.jpg\")  # predict on an image"
      ],
      "metadata": {
        "id": "ziG6Xq1ByKW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results2 = model(\"/content/WhatsApp Image 2023-11-29 at 4.00.21 PM.jpeg\")  # predict on an image"
      ],
      "metadata": {
        "id": "A5mdb2QYf8-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Track\n",
        "- Track mode is used for tracking objects in real-time using a YOLOv8 model. In this mode, the model is loaded from a checkpoint file, and the user can provide a live video stream to perform real-time object tracking.\n",
        "\n",
        "\n",
        "Object detection in VIDEO"
      ],
      "metadata": {
        "id": "SrpBtM9Bg2LO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Track with the model\n",
        "results = model.track(source=\"https://www.youtube.com/watch?v=xSwAACQa3eE\", show=True)  # Tracking with default tracker"
      ],
      "metadata": {
        "id": "u3uuz3ongv21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "XHQzCKTLiltp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the YOLO model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Tune hyperparameters\n",
        "model.tune(data=\"/content/garbage_sub/data.yaml\", epochs=10, iterations=2, optimizer='AdamW', plots=False, save=False, val=False)"
      ],
      "metadata": {
        "id": "z28RrHj3imMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76f75738-dc2b-4725-e7b8-681b62186a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 94.0MB/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mTuner: \u001b[0mInitialized Tuner instance with 'tune_dir=runs/detect/tune'\n",
            "\u001b[34m\u001b[1mTuner: \u001b[0m💡 Learn about tuning at https://docs.ultralytics.com/guides/hyperparameter-tuning\n",
            "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 1/2 with hyperparameters: {'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Hyperparameter Tuning with Ray Tune**\n",
        "- Ray Tune is a hyperparameter tuning library designed for efficiency and flexibility. It supports various search strategies, parallelism, and early stopping strategies\n",
        "\n",
        "https://docs.ultralytics.com/integrations/ray-tune/#processing-ray-tune-results\n",
        "\n",
        "\n",
        "Custom Search Space\n",
        "- Here, we provide a custom search space for the initial learning rate lr0"
      ],
      "metadata": {
        "id": "QIyvSGXu4Xmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw_SGelMPyF9",
        "outputId": "0039d06e-209f-4ca2-a3de-4cea57795499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and update Ultralytics and Ray Tune packages\n",
        "!pip install -U ultralytics \"ray[tune]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpqQY2uI5KCe",
        "outputId": "5221bb4c-0381-43f6-ae3b-b27923fd02b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.0.226)\n",
            "Collecting ray[tune]\n",
            "  Downloading ray-2.8.1-cp310-cp310-manylinux2014_x86_64.whl (62.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.13.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (23.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.4.0)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune])\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (9.0.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2023.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: tensorboardX, ray\n",
            "Successfully installed ray-2.8.1 tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ray import tune"
      ],
      "metadata": {
        "id": "Y4R-DiLeuxD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the YOLO model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Run Ray Tune on the model\n",
        "result_grid = model.tune(data = \"/content/garbage_sub/data.yaml\",\n",
        "                         space = {\"lr0\": tune.uniform(1e-5, 1e-1), \"weight_decay\": tune.uniform(0.0, 0.001), \"box\": tune.uniform(0.02, 0.2), \"cls\": tune.uniform(0.2, 4.0)},\n",
        "                         epochs = 50,\n",
        "                         use_ray = True)"
      ],
      "metadata": {
        "id": "KINxMzUCimuZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9caaac2c-5868-4542-fc41-82552ee33f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 218MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💡 Learn about RayTune at https://docs.ultralytics.com/integrations/ray-tune\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "2023-12-10 19:46:27,023\tINFO worker.py:1673 -- Started a local Ray instance.\n",
            "2023-12-10 19:46:32,048\tINFO tune.py:595 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------+\n",
            "| Configuration for experiment     _tune_2023-12-10_19-46-32   |\n",
            "+--------------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator       |\n",
            "| Scheduler                        AsyncHyperBandScheduler     |\n",
            "| Number of trials                 10                          |\n",
            "+--------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/runs/detect/tune/_tune_2023-12-10_19-46-32\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/_tune_2023-12-10_19-46-32`\n",
            "\n",
            "Trial status: 10 PENDING\n",
            "Current time: 2023-12-10 19:46:33. Total running time: 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+----------------------------------------------------------------------------------+\n",
            "| Trial name          status           lr0     weight_decay         box        cls |\n",
            "+----------------------------------------------------------------------------------+\n",
            "| _tune_d17f8_00000   PENDING    0.0715976      0.000702957   0.100073    3.08679  |\n",
            "| _tune_d17f8_00001   PENDING    0.0314152      0.000497117   0.135236    2.09464  |\n",
            "| _tune_d17f8_00002   PENDING    0.0665498      0.000428936   0.0989968   1.89262  |\n",
            "| _tune_d17f8_00003   PENDING    0.0826701      0.000610564   0.184469    0.288398 |\n",
            "| _tune_d17f8_00004   PENDING    0.0523077      0.000665299   0.0569945   0.313019 |\n",
            "| _tune_d17f8_00005   PENDING    0.0765905      0.000365199   0.100079    2.55025  |\n",
            "| _tune_d17f8_00006   PENDING    0.0442221      0.000871829   0.148009    2.28271  |\n",
            "| _tune_d17f8_00007   PENDING    0.0940426      3.85363e-05   0.174762    2.05387  |\n",
            "| _tune_d17f8_00008   PENDING    0.0524804      0.000789866   0.186999    3.95339  |\n",
            "| _tune_d17f8_00009   PENDING    0.0921252      0.000610561   0.0827056   1.24079  |\n",
            "+----------------------------------------------------------------------------------+\n",
            "\n",
            "Trial _tune_d17f8_00000 started with configuration:\n",
            "+---------------------------------------------------------+\n",
            "| Trial _tune_d17f8_00000 config                          |\n",
            "+---------------------------------------------------------+\n",
            "| box                                             0.10007 |\n",
            "| cls                                             3.08679 |\n",
            "| data                               ...age_sub/data.yaml |\n",
            "| lr0                                              0.0716 |\n",
            "| weight_decay                                     0.0007 |\n",
            "+---------------------------------------------------------+\n",
            "\n",
            "Trial _tune_d17f8_00001 started with configuration:\n",
            "+---------------------------------------------------------+\n",
            "| Trial _tune_d17f8_00001 config                          |\n",
            "+---------------------------------------------------------+\n",
            "| box                                             0.13524 |\n",
            "| cls                                             2.09464 |\n",
            "| data                               ...age_sub/data.yaml |\n",
            "| lr0                                             0.03142 |\n",
            "| weight_decay                                     0.0005 |\n",
            "+---------------------------------------------------------+\n",
            "\u001b[36m(_tune pid=2187)\u001b[0m Ultralytics YOLOv8.0.226 🚀 Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[36m(_tune pid=2187)\u001b[0m \u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/garbage_sub/data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.03141524203112329, lrf=0.01, momentum=0.937, weight_decay=0.0004971165583465277, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.13523586546655655, cls=2.0946369231796007, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "\u001b[36m(_tune pid=2187)\u001b[0m Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_tune pid=2187)\u001b[0m \r  0%|          | 0.00/755k [00:00<?, ?B/s]\r100%|██████████| 755k/755k [00:00<00:00, 71.7MB/s]\n",
            "\u001b[36m(_tune pid=2187)\u001b[0m 2023-12-10 19:46:53.313853: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_tune pid=2187)\u001b[0m 2023-12-10 19:46:53.313929: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_tune pid=2187)\u001b[0m 2023-12-10 19:46:53.313969: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_tune pid=2187)\u001b[0m Overriding model.yaml nc=80 with nc=1\n",
            "\u001b[36m(_tune pid=2187)\u001b[0m \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m                    from  n    params  module                                       arguments                     \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m   0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m   1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m   2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m   3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m   4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m   5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m   6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m   7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "\u001b[36m(_tune pid=2186)\u001b[0m Ultralytics YOLOv8.0.226 🚀 Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m \u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/garbage_sub/data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.07159764885777244, lrf=0.01, momentum=0.937, weight_decay=0.0007029573223966049, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.10007277276536723, cls=3.0867872644970675, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "\u001b[36m(_tune pid=2187)\u001b[0m   8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m   9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m  10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m  11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m  12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m  13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m  14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m  15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m  16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m  17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m  18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m  19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m  20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m  21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m  22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "\u001b[36m(_tune pid=2187)\u001b[0m Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
            "\u001b[36m(_tune pid=2187)\u001b[0m Transferred 319/355 items from pretrained weights\n",
            "\u001b[36m(_tune pid=2187)\u001b[0m \u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "\u001b[36m(_tune pid=2187)\u001b[0m Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_tune pid=2187)\u001b[0m \r\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/garbage_sub/train/labels...:   0%|          | 0/295 [00:00<?, ?it/s]\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m \r  0%|          | 0.00/755k [00:00<?, ?B/s]\r100%|██████████| 755k/755k [00:00<00:00, 65.5MB/s]\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m 2023-12-10 19:46:53.319632: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m 2023-12-10 19:46:53.319702: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m 2023-12-10 19:46:53.319739: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/garbage_sub/train/labels... 126 images, 6 backgrounds, 0 corrupt:  43%|████▎     | 126/295 [00:00<00:00, 1155.02it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/garbage_sub/train/labels... 295 images, 8 backgrounds, 0 corrupt: 100%|██████████| 295/295 [00:00<00:00, 1596.27it/s]\n",
            "2023-12-10 19:46:59,616\tWARNING worker.py:2074 -- Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1669, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1769, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1675, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1615, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 726, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 91, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/tuner.py\", line 104, in _tune\n",
            "    results = model_to_train.train(**config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 338, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 190, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 286, in _do_train\n",
            "    self._setup_train(world_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 251, in _setup_train\n",
            "    self.train_loader = self.get_dataloader(self.trainset, batch_size=batch_size, rank=RANK, mode='train')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/detect/train.py\", line 46, in get_dataloader\n",
            "    dataset = self.build_dataset(dataset_path, mode, batch_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/detect/train.py\", line 40, in build_dataset\n",
            "    return build_yolo_dataset(self.args, img_path, batch, self.data, mode=mode, rect=mode == 'val', stride=gs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/build.py\", line 80, in build_yolo_dataset\n",
            "    return YOLODataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\", line 41, in __init__\n",
            "    super().__init__(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/base.py\", line 73, in __init__\n",
            "    self.labels = self.get_labels()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\", line 106, in get_labels\n",
            "    cache, exists = self.cache_labels(cache_path), False  # run cache ops\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\", line 94, in cache_labels\n",
            "    save_dataset_cache_file(self.prefix, path, x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\", line 319, in save_dataset_cache_file\n",
            "    path.with_suffix('.cache.npy').rename(path)  # remove .npy suffix\n",
            "  File \"/usr/lib/python3.10/pathlib.py\", line 1234, in rename\n",
            "    self._accessor.rename(self, target)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/garbage_sub/train/labels.cache.npy' -> '/content/garbage_sub/train/labels.cache'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 733, in dump\n",
            "    return Pickler.dump(self, obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 826, in reducer_override\n",
            "    if sys.version_info[:2] < (3, 7) and _is_parametrized_type_hint(\n",
            "RecursionError: maximum recursion depth exceeded in comparison\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 2064, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1960, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1617, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1618, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 948, in ray._raylet.store_task_errors\n",
            "  File \"python/ray/_raylet.pyx\", line 4215, in ray._raylet.CoreWorker.store_task_outputs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 494, in serialize\n",
            "    return self._serialize_to_msgpack(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 449, in _serialize_to_msgpack\n",
            "    value = value.to_bytes()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 32, in to_bytes\n",
            "    serialized_exception=pickle.dumps(self),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 88, in dumps\n",
            "    cp.dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 739, in dump\n",
            "    raise pickle.PicklingError(msg) from e\n",
            "_pickle.PicklingError: Could not pickle object as excessively deep recursion required.\n",
            "An unexpected internal error occurred while the worker was executing a task.\n",
            "2023-12-10 19:46:59,628\tWARNING worker.py:2074 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffe062e7b41958bf81d0d8479501000000 Worker ID: 7425c23d9a7fbc3f4bdb90c51c6a695b2835b0c78bdcbf9e4c513e17 Node ID: 9f061cf47d55343b75c9fe875a80c4cf7d2dea0acc5d0e7bd60c3173 Worker IP address: 172.28.0.12 Worker port: 33429 Worker PID: 2187 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1669, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1769, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1675, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1615, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 726, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 91, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/tuner.py\", line 104, in _tune\n",
            "    results = model_to_train.train(**config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 338, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 190, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 286, in _do_train\n",
            "    self._setup_train(world_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 251, in _setup_train\n",
            "    self.train_loader = self.get_dataloader(self.trainset, batch_size=batch_size, rank=RANK, mode='train')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/detect/train.py\", line 46, in get_dataloader\n",
            "    dataset = self.build_dataset(dataset_path, mode, batch_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/detect/train.py\", line 40, in build_dataset\n",
            "    return build_yolo_dataset(self.args, img_path, batch, self.data, mode=mode, rect=mode == 'val', stride=gs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/build.py\", line 80, in build_yolo_dataset\n",
            "    return YOLODataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\", line 41, in __init__\n",
            "    super().__init__(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/base.py\", line 73, in __init__\n",
            "    self.labels = self.get_labels()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\", line 106, in get_labels\n",
            "    cache, exists = self.cache_labels(cache_path), False  # run cache ops\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\", line 94, in cache_labels\n",
            "    save_dataset_cache_file(self.prefix, path, x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\", line 319, in save_dataset_cache_file\n",
            "    path.with_suffix('.cache.npy').rename(path)  # remove .npy suffix\n",
            "  File \"/usr/lib/python3.10/pathlib.py\", line 1234, in rename\n",
            "    self._accessor.rename(self, target)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/garbage_sub/train/labels.cache.npy' -> '/content/garbage_sub/train/labels.cache'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 733, in dump\n",
            "    return Pickler.dump(self, obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 826, in reducer_override\n",
            "    if sys.version_info[:2] < (3, 7) and _is_parametrized_type_hint(\n",
            "RecursionError: maximum recursion depth exceeded in comparison\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 2064, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1960, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1617, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1618, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 948, in ray._raylet.store_task_errors\n",
            "  File \"python/ray/_raylet.pyx\", line 4215, in ray._raylet.CoreWorker.store_task_outputs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 494, in serialize\n",
            "    return self._serialize_to_msgpack(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 449, in _serialize_to_msgpack\n",
            "    value = value.to_bytes()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 32, in to_bytes\n",
            "    serialized_exception=pickle.dumps(self),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 88, in dumps\n",
            "    cp.dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 739, in dump\n",
            "    raise pickle.PicklingError(msg) from e\n",
            "_pickle.PicklingError: Could not pickle object as excessively deep recursion required.\n",
            "An unexpected internal error occurred while the worker was executing a task.\n",
            "2023-12-10 19:46:59,638\tERROR tune_controller.py:1383 -- Trial task failed for trial _tune_d17f8_00001\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2565, in get\n",
            "    raise value\n",
            "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
            "\tclass_name: ImplicitFunc\n",
            "\tactor_id: e062e7b41958bf81d0d8479501000000\n",
            "\tpid: 2187\n",
            "\tnamespace: 5d452863-ac91-4912-aa69-2ffdfb7764d1\n",
            "\tip: 172.28.0.12\n",
            "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1669, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1769, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1675, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1615, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 726, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 91, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/tuner.py\", line 104, in _tune\n",
            "    results = model_to_train.train(**config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 338, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 190, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 286, in _do_train\n",
            "    self._setup_train(world_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 251, in _setup_train\n",
            "    self.train_loader = self.get_dataloader(self.trainset, batch_size=batch_size, rank=RANK, mode='train')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/detect/train.py\", line 46, in get_dataloader\n",
            "    dataset = self.build_dataset(dataset_path, mode, batch_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/detect/train.py\", line 40, in build_dataset\n",
            "    return build_yolo_dataset(self.args, img_path, batch, self.data, mode=mode, rect=mode == 'val', stride=gs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/build.py\", line 80, in build_yolo_dataset\n",
            "    return YOLODataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\", line 41, in __init__\n",
            "    super().__init__(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/base.py\", line 73, in __init__\n",
            "    self.labels = self.get_labels()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\", line 106, in get_labels\n",
            "    cache, exists = self.cache_labels(cache_path), False  # run cache ops\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\", line 94, in cache_labels\n",
            "    save_dataset_cache_file(self.prefix, path, x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\", line 319, in save_dataset_cache_file\n",
            "    path.with_suffix('.cache.npy').rename(path)  # remove .npy suffix\n",
            "  File \"/usr/lib/python3.10/pathlib.py\", line 1234, in rename\n",
            "    self._accessor.rename(self, target)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/garbage_sub/train/labels.cache.npy' -> '/content/garbage_sub/train/labels.cache'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 733, in dump\n",
            "    return Pickler.dump(self, obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 826, in reducer_override\n",
            "    if sys.version_info[:2] < (3, 7) and _is_parametrized_type_hint(\n",
            "RecursionError: maximum recursion depth exceeded in comparison\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 2064, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1960, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1617, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1618, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1856, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 948, in ray._raylet.store_task_errors\n",
            "  File \"python/ray/_raylet.pyx\", line 4215, in ray._raylet.CoreWorker.store_task_outputs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 494, in serialize\n",
            "    return self._serialize_to_msgpack(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 449, in _serialize_to_msgpack\n",
            "    value = value.to_bytes()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 32, in to_bytes\n",
            "    serialized_exception=pickle.dumps(self),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 88, in dumps\n",
            "    cp.dump(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/cloudpickle/cloudpickle_fast.py\", line 739, in dump\n",
            "    raise pickle.PicklingError(msg) from e\n",
            "_pickle.PicklingError: Could not pickle object as excessively deep recursion required.\n",
            "An unexpected internal error occurred while the worker was executing a task.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_tune pid=2186)\u001b[0m \u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/garbage_sub/train/labels.cache\n",
            "\n",
            "Trial _tune_d17f8_00001 errored after 0 iterations at 2023-12-10 19:46:59. Total running time: 26s\n",
            "Error file: /root/ray_results/_tune_2023-12-10_19-46-32/_tune_d17f8_00001_1_box=0.1352,cls=2.0946,lr0=0.0314,weight_decay=0.0005_2023-12-10_19-46-32/error.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_tune pid=2186)\u001b[0m \r\u001b[34m\u001b[1mval: \u001b[0mScanning /content/garbage_sub/valid/labels...:   0%|          | 0/28 [00:00<?, ?it/s]\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m \r\u001b[34m\u001b[1mval: \u001b[0mScanning /content/garbage_sub/valid/labels... 28 images, 3 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<00:00, 731.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_tune pid=2186)\u001b[0m \u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/garbage_sub/valid/labels.cache\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m Plotting labels to runs/detect/train/labels.jpg... \n",
            "\n",
            "Trial status: 1 RUNNING | 1 ERROR | 8 PENDING\n",
            "Current time: 2023-12-10 19:47:03. Total running time: 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+----------------------------------------------------------------------------------+\n",
            "| Trial name          status           lr0     weight_decay         box        cls |\n",
            "+----------------------------------------------------------------------------------+\n",
            "| _tune_d17f8_00000   RUNNING    0.0715976      0.000702957   0.100073    3.08679  |\n",
            "| _tune_d17f8_00002   PENDING    0.0665498      0.000428936   0.0989968   1.89262  |\n",
            "| _tune_d17f8_00003   PENDING    0.0826701      0.000610564   0.184469    0.288398 |\n",
            "| _tune_d17f8_00004   PENDING    0.0523077      0.000665299   0.0569945   0.313019 |\n",
            "| _tune_d17f8_00005   PENDING    0.0765905      0.000365199   0.100079    2.55025  |\n",
            "| _tune_d17f8_00006   PENDING    0.0442221      0.000871829   0.148009    2.28271  |\n",
            "| _tune_d17f8_00007   PENDING    0.0940426      3.85363e-05   0.174762    2.05387  |\n",
            "| _tune_d17f8_00008   PENDING    0.0524804      0.000789866   0.186999    3.95339  |\n",
            "| _tune_d17f8_00009   PENDING    0.0921252      0.000610561   0.0827056   1.24079  |\n",
            "| _tune_d17f8_00001   ERROR      0.0314152      0.000497117   0.135236    2.09464  |\n",
            "+----------------------------------------------------------------------------------+\n",
            "\n",
            "Trial _tune_d17f8_00002 started with configuration:\n",
            "+---------------------------------------------------------+\n",
            "| Trial _tune_d17f8_00002 config                          |\n",
            "+---------------------------------------------------------+\n",
            "| box                                               0.099 |\n",
            "| cls                                             1.89262 |\n",
            "| data                               ...age_sub/data.yaml |\n",
            "| lr0                                             0.06655 |\n",
            "| weight_decay                                    0.00043 |\n",
            "+---------------------------------------------------------+\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m \u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.07159764885777244' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[36m(_tune pid=2186)\u001b[0m \u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0007029573223966049), 63 bias(decay=0.0)\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m Overriding model.yaml nc=80 with nc=1\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m \u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\u001b[32m [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m                    from  n    params  module                                       arguments                     \n",
            "\u001b[36m(_tune pid=2186)\u001b[0m  19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m   8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m   9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            "\u001b[36m(_tune pid=2186)\u001b[0m  13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m  20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m  22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "\u001b[36m(_tune pid=2186)\u001b[0m Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m Transferred 319/355 items from pretrained weights\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m \u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[36m(_tune pid=2417)\u001b[0m Ultralytics YOLOv8.0.226 🚀 Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[36m(_tune pid=2417)\u001b[0m \u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/garbage_sub/data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.06654983008233765, lrf=0.01, momentum=0.937, weight_decay=0.0004289363372981021, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.09899676710234757, cls=1.892623639977826, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_tune pid=2417)\u001b[0m 2023-12-10 19:47:15.692549: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_tune pid=2417)\u001b[0m 2023-12-10 19:47:15.692620: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_tune pid=2417)\u001b[0m 2023-12-10 19:47:15.692663: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m \r\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/garbage_sub/train/labels...:   0%|          | 0/295 [00:00<?, ?it/s]\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m \r\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/garbage_sub/train/labels... 109 images, 5 backgrounds, 0 corrupt:  37%|███▋      | 109/295 [00:00<00:00, 1061.92it/s]\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m \r\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/garbage_sub/train/labels... 295 images, 8 backgrounds, 0 corrupt: 100%|██████████| 295/295 [00:00<00:00, 1592.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_tune pid=2186)\u001b[0m Image sizes 640 train, 640 val\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m Using 0 dataloader workers\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m Starting training for 50 epochs...\n",
            "\u001b[36m(_tune pid=2186)\u001b[0m \n",
            "\u001b[36m(_tune pid=2186)\u001b[0m       Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_tune pid=2186)\u001b[0m \r  0%|          | 0/19 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_tune pid=2417)\u001b[0m Overriding model.yaml nc=80 with nc=1\n",
            "\u001b[36m(_tune pid=2417)\u001b[0m                    from  n    params  module                                       arguments                     \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m   0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m   1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m   2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m   3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m   4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m   5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m   6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m   7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m   8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m   9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m  10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m  11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m  13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m  14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m  16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m  17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m  19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m  20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m  22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
            "\u001b[36m(_tune pid=2417)\u001b[0m Transferred 319/355 items from pretrained weights\n",
            "\u001b[36m(_tune pid=2417)\u001b[0m \u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "\u001b[36m(_tune pid=2417)\u001b[0m Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/garbage_sub/train/labels.cache... 295 images, 8 backgrounds, 0 corrupt: 100%|██████████| 295/295 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/garbage_sub/valid/labels.cache... 28 images, 3 backgrounds, 0 corrupt: 100%|██████████| 28/28 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_tune pid=2417)\u001b[0m Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m \u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.06654983008233765' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[36m(_tune pid=2417)\u001b[0m \u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0004289363372981021), 63 bias(decay=0.0)\n",
            "\u001b[36m(_tune pid=2417)\u001b[0m \u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\n",
            "Trial status: 2 RUNNING | 1 ERROR | 7 PENDING\n",
            "Current time: 2023-12-10 19:47:33. Total running time: 1min 0s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+----------------------------------------------------------------------------------+\n",
            "| Trial name          status           lr0     weight_decay         box        cls |\n",
            "+----------------------------------------------------------------------------------+\n",
            "| _tune_d17f8_00000   RUNNING    0.0715976      0.000702957   0.100073    3.08679  |\n",
            "| _tune_d17f8_00002   RUNNING    0.0665498      0.000428936   0.0989968   1.89262  |\n",
            "| _tune_d17f8_00003   PENDING    0.0826701      0.000610564   0.184469    0.288398 |\n",
            "| _tune_d17f8_00004   PENDING    0.0523077      0.000665299   0.0569945   0.313019 |\n",
            "| _tune_d17f8_00005   PENDING    0.0765905      0.000365199   0.100079    2.55025  |\n",
            "| _tune_d17f8_00006   PENDING    0.0442221      0.000871829   0.148009    2.28271  |\n",
            "| _tune_d17f8_00007   PENDING    0.0940426      3.85363e-05   0.174762    2.05387  |\n",
            "| _tune_d17f8_00008   PENDING    0.0524804      0.000789866   0.186999    3.95339  |\n",
            "| _tune_d17f8_00009   PENDING    0.0921252      0.000610561   0.0827056   1.24079  |\n",
            "| _tune_d17f8_00001   ERROR      0.0314152      0.000497117   0.135236    2.09464  |\n",
            "+----------------------------------------------------------------------------------+\n",
            "\u001b[36m(_tune pid=2417)\u001b[0m Image sizes 640 train, 640 val\n",
            "\u001b[36m(_tune pid=2417)\u001b[0m Using 0 dataloader workers\n",
            "\u001b[36m(_tune pid=2417)\u001b[0m Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "\u001b[36m(_tune pid=2417)\u001b[0m Starting training for 50 epochs...\n",
            "\u001b[36m(_tune pid=2417)\u001b[0m       Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[36m(_tune pid=2417)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]\n",
            "       1/50         0G    0.02481      18.06      2.202         47        640:   5%|▌         | 1/19 [00:26<07:52, 26.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 2 RUNNING | 1 ERROR | 7 PENDING\n",
            "Current time: 2023-12-10 19:48:03. Total running time: 1min 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+----------------------------------------------------------------------------------+\n",
            "| Trial name          status           lr0     weight_decay         box        cls |\n",
            "+----------------------------------------------------------------------------------+\n",
            "| _tune_d17f8_00000   RUNNING    0.0715976      0.000702957   0.100073    3.08679  |\n",
            "| _tune_d17f8_00002   RUNNING    0.0665498      0.000428936   0.0989968   1.89262  |\n",
            "| _tune_d17f8_00003   PENDING    0.0826701      0.000610564   0.184469    0.288398 |\n",
            "| _tune_d17f8_00004   PENDING    0.0523077      0.000665299   0.0569945   0.313019 |\n",
            "| _tune_d17f8_00005   PENDING    0.0765905      0.000365199   0.100079    2.55025  |\n",
            "| _tune_d17f8_00006   PENDING    0.0442221      0.000871829   0.148009    2.28271  |\n",
            "| _tune_d17f8_00007   PENDING    0.0940426      3.85363e-05   0.174762    2.05387  |\n",
            "| _tune_d17f8_00008   PENDING    0.0524804      0.000789866   0.186999    3.95339  |\n",
            "| _tune_d17f8_00009   PENDING    0.0921252      0.000610561   0.0827056   1.24079  |\n",
            "| _tune_d17f8_00001   ERROR      0.0314152      0.000497117   0.135236    2.09464  |\n",
            "+----------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50         0G    0.02454      11.07      2.202         47        640:   5%|▌         | 1/19 [00:28<08:31, 28.44s/it]\n",
            "       1/50         0G     0.0228      17.33      2.069         48        640:  11%|█         | 2/19 [00:56<08:07, 28.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 2 RUNNING | 1 ERROR | 7 PENDING\n",
            "Current time: 2023-12-10 19:48:33. Total running time: 2min 0s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+----------------------------------------------------------------------------------+\n",
            "| Trial name          status           lr0     weight_decay         box        cls |\n",
            "+----------------------------------------------------------------------------------+\n",
            "| _tune_d17f8_00000   RUNNING    0.0715976      0.000702957   0.100073    3.08679  |\n",
            "| _tune_d17f8_00002   RUNNING    0.0665498      0.000428936   0.0989968   1.89262  |\n",
            "| _tune_d17f8_00003   PENDING    0.0826701      0.000610564   0.184469    0.288398 |\n",
            "| _tune_d17f8_00004   PENDING    0.0523077      0.000665299   0.0569945   0.313019 |\n",
            "| _tune_d17f8_00005   PENDING    0.0765905      0.000365199   0.100079    2.55025  |\n",
            "| _tune_d17f8_00006   PENDING    0.0442221      0.000871829   0.148009    2.28271  |\n",
            "| _tune_d17f8_00007   PENDING    0.0940426      3.85363e-05   0.174762    2.05387  |\n",
            "| _tune_d17f8_00008   PENDING    0.0524804      0.000789866   0.186999    3.95339  |\n",
            "| _tune_d17f8_00009   PENDING    0.0921252      0.000610561   0.0827056   1.24079  |\n",
            "| _tune_d17f8_00001   ERROR      0.0314152      0.000497117   0.135236    2.09464  |\n",
            "+----------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50         0G    0.02255      10.63      2.069         48        640:  11%|█         | 2/19 [00:57<08:08, 28.72s/it]\n",
            "       1/50         0G    0.02168      17.59      2.018         35        640:  16%|█▌        | 3/19 [01:23<07:26, 27.90s/it]\n",
            "2023-12-10 19:48:53,696\tWARNING worker.py:2074 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffd01a32153be98a14978280f701000000 Worker ID: 2ea3eb907a5b3c99d6a83126e160786f700bd526615fbb5854a6b73c Node ID: 9f061cf47d55343b75c9fe875a80c4cf7d2dea0acc5d0e7bd60c3173 Worker IP address: 172.28.0.12 Worker port: 38803 Worker PID: 2186 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\u001b[0m in \u001b[0;36mresolve_future\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\u001b[0m in \u001b[0;36mauto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mauto_init_ray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2564\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2565\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: Task was killed due to the node running low on memory.\nMemory on the node (IP: 172.28.0.12, ID: 9f061cf47d55343b75c9fe875a80c4cf7d2dea0acc5d0e7bd60c3173) where the task (actor ID: 2945179d83f43fa4a4dc767a01000000, name=ImplicitFunc.__init__, pid=2417, memory used=5.33GB) was running was 12.08GB / 12.68GB (0.953014), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 380c8314a082ec1582ad0831cda26e99af281c23f2792612f062b953) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.28.0.12`. To see the logs of the worker, use `ray logs worker-380c8314a082ec1582ad0831cda26e99af281c23f2792612f062b953*out -ip 172.28.0.12. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n2417\t5.33\tray::ImplicitFunc.train\n124\t0.38\t/usr/bin/python3 -m colab_kernel_launcher -f /root/.local/share/jupyter/runtime/kernel-2f36f08c-c218...\n1867\t0.35\tnode /datalab/web/pyright/pyright-langserver.js --stdio --cancellationReceive=file:065cd56c367f68aee...\n77\t0.09\t/usr/bin/python3 /usr/local/bin/jupyter-notebook --debug --transport=\"ipc\" --ip=172.28.0.12 --Notebo...\n1990\t0.05\t/usr/bin/python3 /usr/local/lib/python3.10/dist-packages/ray/dashboard/dashboard.py --host=127.0.0.1...\n2047\t0.05\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/dashboard/agent.py --node-ip-address...\n1988\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/autoscaler/_private/monitor.py --log...\n2012\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/_private/log_monitor.py --session-di...\n2049\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/_private/runtime_env/agent/main.py -...\n60\t0.03\tpython3 /usr/local/bin/colab-fileshim.py\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b7b959e82221>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Run Ray Tune on the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m result_grid = model.tune(data = \"/content/garbage_sub/data.yaml\",\n\u001b[0m\u001b[1;32m      6\u001b[0m                          \u001b[0mspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"lr0\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"weight_decay\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"box\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cls\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                          \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtune\u001b[0;34m(self, use_ray, iterations, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_ray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_ray_tune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mrun_ray_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtuner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTuner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/tuner.py\u001b[0m in \u001b[0;36mrun_ray_tune\u001b[0;34m(model, space, grace_period, gpu_per_trial, max_samples, **train_args)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;31m# Run the hyperparameter search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;31m# Return the results of the hyperparameter search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/tuner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_ray_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTuneError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                 raise TuneError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/impl/tuner_internal.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mparam_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_restored\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/impl/tuner_internal.py\u001b[0m in \u001b[0;36m_fit_internal\u001b[0;34m(self, trainable, param_space)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tuner_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         }\n\u001b[0;32m--> 645\u001b[0;31m         analysis = run(\n\u001b[0m\u001b[1;32m    646\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _experiment_checkpoint_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexperiment_interrupted_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVerbosity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV1_EXPERIMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m                 \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/execution/tune_controller.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;31m# Handle one event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actor_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m             \u001b[0;31m# If there are no actors running, warn about potentially\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;31m# insufficient resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/actor_manager.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actor_state_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactor_task_futures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actor_task_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_ready_resource_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\u001b[0m in \u001b[0;36mresolve_future\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mon_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/actor_manager.py\u001b[0m in \u001b[0;36mon_error\u001b[0;34m(exception)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mon_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m             self._actor_task_failed(\n\u001b[0m\u001b[1;32m    771\u001b[0m                 \u001b[0mtracked_actor_task\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtracked_actor_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/actor_manager.py\u001b[0m in \u001b[0;36m_actor_task_failed\u001b[0;34m(self, tracked_actor_task, exception)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0mtracked_actor_task\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracked_actor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    292\u001b[0m                 \u001b[0;34mf\"Caught unexpected exception: {exception}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             ) from exception\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught unexpected exception: Task was killed due to the node running low on memory.\nMemory on the node (IP: 172.28.0.12, ID: 9f061cf47d55343b75c9fe875a80c4cf7d2dea0acc5d0e7bd60c3173) where the task (actor ID: 2945179d83f43fa4a4dc767a01000000, name=ImplicitFunc.__init__, pid=2417, memory used=5.33GB) was running was 12.08GB / 12.68GB (0.953014), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 380c8314a082ec1582ad0831cda26e99af281c23f2792612f062b953) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.28.0.12`. To see the logs of the worker, use `ray logs worker-380c8314a082ec1582ad0831cda26e99af281c23f2792612f062b953*out -ip 172.28.0.12. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n2417\t5.33\tray::ImplicitFunc.train\n124\t0.38\t/usr/bin/python3 -m colab_kernel_launcher -f /root/.local/share/jupyter/runtime/kernel-2f36f08c-c218...\n1867\t0.35\tnode /datalab/web/pyright/pyright-langserver.js --stdio --cancellationReceive=file:065cd56c367f68aee...\n77\t0.09\t/usr/bin/python3 /usr/local/bin/jupyter-notebook --debug --transport=\"ipc\" --ip=172.28.0.12 --Notebo...\n1990\t0.05\t/usr/bin/python3 /usr/local/lib/python3.10/dist-packages/ray/dashboard/dashboard.py --host=127.0.0.1...\n2047\t0.05\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/dashboard/agent.py --node-ip-address...\n1988\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/autoscaler/_private/monitor.py --log...\n2012\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/_private/log_monitor.py --session-di...\n2049\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/_private/runtime_env/agent/main.py -...\n60\t0.03\tpython3 /usr/local/bin/colab-fileshim.py\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Tune Experiment Results from a Directory"
      ],
      "metadata": {
        "id": "ZWpu97A65Vor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_path = f\"{storage_path}/{exp_name}\"\n",
        "print(f\"Loading results from {experiment_path}...\")\n",
        "\n",
        "restored_tuner = tune.Tuner.restore(experiment_path, trainable=train_mnist)\n",
        "result_grid = restored_tuner.get_results()"
      ],
      "metadata": {
        "id": "x5xr9M7u5VeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the Entire History of Reported Metrics for a Trial"
      ],
      "metadata": {
        "id": "eVxSMm9M5dlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for result in result_grid:\n",
        "    plt.plot(result.metrics_dataframe[\"training_iteration\"], result.metrics_dataframe[\"mean_accuracy\"], label=f\"Trial {i}\")\n",
        "\n",
        "plt.xlabel('Training Iterations')\n",
        "plt.ylabel('Mean Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6nRkZfgI5Vba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iqiFUdv_5VZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mj9R2E-R5VWN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}